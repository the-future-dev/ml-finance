{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-02 17:56:20.692947: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-12-02 17:56:20.721624: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-02 17:56:20.721657: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-02 17:56:20.721675: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-02 17:56:20.727140: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-02 17:56:21.353131: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import load_model\n",
    "from keras.regularizers import l2\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from shared import read_dataset, plot_results, evaluate_price_predictions, mean_abs_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Trading Days: (3284, 23)\n"
     ]
    }
   ],
   "source": [
    "start = \"2010-01-01\"\n",
    "end = \"2023-01-01\"\n",
    "target_column_name = 'Close'\n",
    "path = '../models/lstm_model/predictor_adj_close.h5'\n",
    "\n",
    "AZM = read_dataset('../data/AZM.MI_ta.csv', start, end)\n",
    "\n",
    "data = AZM\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "cols = [target_column_name] + [ col for col in data if col != target_column_name]\n",
    "target_column = list(data.columns).index(target_column_name)\n",
    "data = data[cols]\n",
    "\n",
    "print(f\"#Trading Days: {data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Trading Days: (2495, 21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQUENCE_LENGTH = 100\n",
    "PREDICTION_LENGTH = 5\n",
    "\n",
    "# Define feature array and target array to train the model.\n",
    "data_array = np.array(data.values)\n",
    "target_array = np.array(data[target_column_name].values).reshape(-1, 1)\n",
    "\n",
    "# Normalize the data\n",
    "scaler_data = MinMaxScaler()\n",
    "scaler_data.fit(data_array)\n",
    "data_array = scaler_data.transform(data_array)\n",
    "\n",
    "scaler_target = MinMaxScaler()\n",
    "scaler_target.fit(target_array)\n",
    "target_array = scaler_target.transform(target_array)\n",
    "\n",
    "# Split the data\n",
    "train_size = int(len(data_array) * 0.90)\n",
    "evaluation_size = int(len(data_array) * 0.0) # no evaluation\n",
    "\n",
    "def create_sequences(data, target, seq_length, pred_length):\n",
    "    sequence_data = []\n",
    "    sequence_target = []\n",
    "    for i in range(seq_length, len(data) - pred_length + 1):\n",
    "        sequence_data.append(data[i - seq_length:i])\n",
    "        sequence_target.append(target[i:i + pred_length].flatten())\n",
    "    return np.array(sequence_data), np.array(sequence_target)\n",
    "\n",
    "data_sequences, target_sequences = create_sequences(data_array, target_array, SEQUENCE_LENGTH, PREDICTION_LENGTH)\n",
    "\n",
    "train_data, validation_data, test_data = data_sequences[:train_size], data_sequences[train_size:train_size+evaluation_size], data_sequences[train_size+evaluation_size:]\n",
    "train_target, validation_target, test_target = target_sequences[:train_size], target_sequences[train_size:train_size+evaluation_size], target_sequences[train_size+evaluation_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A[0]: 17.284999847412106\n",
      "A[1]: 16.909999847412106\n",
      "A[2]: 16.95499992370605\n",
      "A[3]: 16.834999084472656\n",
      "A[4]: 17.149999618530273\n",
      "A[5]: 17.20000076293945\n",
      "A[6]: 17.27499961853027\n",
      "A[7]: 17.360000610351562\n",
      "A[8]: 17.049999237060543\n",
      "A[9]: 17.155000686645504\n",
      "A[10]: 16.57999992370605\n",
      "A[11]: 16.32999992370605\n",
      "A[12]: 16.549999237060547\n",
      "A[13]: 16.53499984741211\n",
      "A[14]: 16.430000305175778\n",
      "A[15]: 15.97000026702881\n",
      "A[16]: 15.949999809265135\n",
      "A[17]: 16.174999237060543\n",
      "A[18]: 15.9350004196167\n",
      "A[19]: 15.59000015258789\n",
      "A[20]: 16.165000915527344\n",
      "A[21]: 15.925000190734863\n",
      "A[22]: 16.0049991607666\n",
      "A[23]: 16.03499984741211\n",
      "A[24]: 15.97000026702881\n",
      "A[25]: 16.399999618530273\n",
      "A[26]: 16.805000305175778\n",
      "A[27]: 16.700000762939453\n",
      "A[28]: 16.690000534057617\n",
      "A[29]: 16.5049991607666\n",
      "A[30]: 16.325000762939453\n",
      "A[31]: 16.434999465942383\n",
      "A[32]: 15.859999656677243\n",
      "A[33]: 15.979999542236326\n",
      "A[34]: 15.574999809265137\n",
      "A[35]: 15.119999885559082\n",
      "A[36]: 15.125\n",
      "A[37]: 14.864999771118162\n",
      "A[38]: 14.720000267028809\n",
      "A[39]: 14.239999771118164\n",
      "A[40]: 14.704999923706056\n",
      "A[41]: 14.944999694824219\n",
      "A[42]: 15.600000381469728\n",
      "A[43]: 15.30500030517578\n",
      "A[44]: 15.09000015258789\n",
      "A[45]: 14.829999923706058\n",
      "A[46]: 14.885000228881836\n",
      "A[47]: 14.739999771118164\n",
      "A[48]: 13.914999961853027\n",
      "A[49]: 14.34000015258789\n",
      "A[50]: 14.859999656677246\n",
      "A[51]: 15.175000190734863\n",
      "A[52]: 15.274999618530272\n",
      "A[53]: 15.260000228881836\n",
      "A[54]: 15.244999885559082\n",
      "A[55]: 15.295000076293945\n",
      "A[56]: 15.77499961853027\n",
      "A[57]: 16.229999542236325\n",
      "A[58]: 16.049999237060543\n",
      "A[59]: 16.354999542236328\n",
      "A[60]: 16.379999160766598\n",
      "A[61]: 16.299999237060547\n",
      "A[62]: 16.340000152587887\n",
      "A[63]: 16.600000381469727\n",
      "A[64]: 16.735000610351562\n",
      "A[65]: 17.014999389648438\n",
      "A[66]: 17.459999084472653\n",
      "A[67]: 17.725000381469723\n",
      "A[68]: 17.82500076293945\n",
      "A[69]: 19.20000076293945\n",
      "A[70]: 19.9950008392334\n",
      "A[71]: 19.790000915527344\n",
      "A[72]: 19.96500015258789\n",
      "A[73]: 19.959999084472656\n",
      "A[74]: 19.924999237060547\n",
      "A[75]: 19.68000030517578\n",
      "A[76]: 19.42000007629394\n",
      "A[77]: 19.5\n",
      "A[78]: 19.610000610351555\n",
      "A[79]: 19.454999923706048\n",
      "A[80]: 19.440000534057614\n",
      "A[81]: 19.190000534057614\n",
      "A[82]: 19.2549991607666\n",
      "A[83]: 19.450000762939453\n",
      "A[84]: 19.334999084472656\n",
      "A[85]: 19.69499969482422\n",
      "A[86]: 19.57500076293945\n",
      "A[87]: 19.57999992370605\n",
      "A[88]: 19.69499969482422\n",
      "A[89]: 19.825000762939453\n",
      "A[90]: 20.090000152587887\n",
      "A[91]: 19.8799991607666\n",
      "A[92]: 20.229999542236325\n",
      "A[93]: 20.11000061035156\n",
      "A[94]: 19.315000534057617\n",
      "A[95]: 20.479999542236328\n",
      "A[96]: 20.46999931335449\n",
      "A[97]: 20.440000534057617\n",
      "A[98]: 20.799999237060543\n",
      "A[99]: 20.610000610351555\n",
      "b: [20.70999908 20.97999954 21.01000023 21.18000031 20.93000031]\n"
     ]
    }
   ],
   "source": [
    "# TESTING CORRECTNESS OF GENERATED SEQUENCES\n",
    "test_index = -1\n",
    "test_column_prompt = 0\n",
    "a = scaler_data.inverse_transform(data_sequences[test_index])\n",
    "b = scaler_target.inverse_transform(target_sequences)\n",
    "\n",
    "for i in range (0, SEQUENCE_LENGTH):\n",
    "    print(f\"A[{i}]: {a[i][test_column_prompt]}\")\n",
    "\n",
    "print(f'b: {b[test_index]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape, l2_value):\n",
    "    \"\"\"LSTM model\"\"\"\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Bidirectional(\n",
    "        keras.layers.LSTM(3, return_sequences=True, kernel_regularizer=l2(l2_value), recurrent_regularizer=l2(l2_value), bias_regularizer=l2(l2_value)),\n",
    "        input_shape=input_shape)\n",
    "    )\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(units=PREDICTION_LENGTH))\n",
    "    return model\n",
    "\n",
    "def train_model(model, train_data, train_target, epochs=30, batch_size=256, patience=20):\n",
    "    model.compile(optimizer='adam', loss='mean_absolute_error')\n",
    "\n",
    "    early_stopping = keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=patience,\n",
    "        verbose=2,\n",
    "        mode='min',\n",
    "        restore_best_weights=True,\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        [train_data], # input\n",
    "        train_target,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        verbose=2,\n",
    "        validation_split=0.2,\n",
    "        callbacks=[early_stopping]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-02 17:56:26.306081: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2023-12-02 17:56:26.306119: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:168] retrieving CUDA diagnostic information for host: andrea\n",
      "2023-12-02 17:56:26.306124: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:175] hostname: andrea\n",
      "2023-12-02 17:56:26.306468: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:199] libcuda reported version is: 535.129.3\n",
      "2023-12-02 17:56:26.306485: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:203] kernel reported version is: 535.129.3\n",
      "2023-12-02 17:56:26.306488: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:309] kernel version seems to match DSO: 535.129.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/900\n",
      "5/5 - 2s - loss: 0.8184 - val_loss: 0.7059 - 2s/epoch - 466ms/step\n",
      "Epoch 2/900\n",
      "5/5 - 0s - loss: 0.6219 - val_loss: 0.5587 - 157ms/epoch - 31ms/step\n",
      "Epoch 3/900\n",
      "5/5 - 0s - loss: 0.5646 - val_loss: 0.5600 - 147ms/epoch - 29ms/step\n",
      "Epoch 4/900\n",
      "5/5 - 0s - loss: 0.5446 - val_loss: 0.5171 - 151ms/epoch - 30ms/step\n",
      "Epoch 5/900\n",
      "5/5 - 0s - loss: 0.5037 - val_loss: 0.5224 - 146ms/epoch - 29ms/step\n",
      "Epoch 6/900\n",
      "5/5 - 0s - loss: 0.4889 - val_loss: 0.4997 - 153ms/epoch - 31ms/step\n",
      "Epoch 7/900\n",
      "5/5 - 0s - loss: 0.4726 - val_loss: 0.4934 - 151ms/epoch - 30ms/step\n",
      "Epoch 8/900\n",
      "5/5 - 0s - loss: 0.4587 - val_loss: 0.4651 - 153ms/epoch - 31ms/step\n",
      "Epoch 9/900\n",
      "5/5 - 0s - loss: 0.4437 - val_loss: 0.4632 - 150ms/epoch - 30ms/step\n",
      "Epoch 10/900\n",
      "5/5 - 0s - loss: 0.4304 - val_loss: 0.4434 - 151ms/epoch - 30ms/step\n",
      "Epoch 11/900\n",
      "5/5 - 0s - loss: 0.4184 - val_loss: 0.4387 - 153ms/epoch - 31ms/step\n",
      "Epoch 12/900\n",
      "5/5 - 0s - loss: 0.4064 - val_loss: 0.4251 - 157ms/epoch - 31ms/step\n",
      "Epoch 13/900\n",
      "5/5 - 0s - loss: 0.3952 - val_loss: 0.4127 - 153ms/epoch - 31ms/step\n",
      "Epoch 14/900\n",
      "5/5 - 0s - loss: 0.3845 - val_loss: 0.4048 - 156ms/epoch - 31ms/step\n",
      "Epoch 15/900\n",
      "5/5 - 0s - loss: 0.3742 - val_loss: 0.3950 - 152ms/epoch - 30ms/step\n",
      "Epoch 16/900\n",
      "5/5 - 0s - loss: 0.3646 - val_loss: 0.3857 - 153ms/epoch - 31ms/step\n",
      "Epoch 17/900\n",
      "5/5 - 0s - loss: 0.3550 - val_loss: 0.3794 - 149ms/epoch - 30ms/step\n",
      "Epoch 18/900\n",
      "5/5 - 0s - loss: 0.3458 - val_loss: 0.3680 - 149ms/epoch - 30ms/step\n",
      "Epoch 19/900\n",
      "5/5 - 0s - loss: 0.3371 - val_loss: 0.3590 - 151ms/epoch - 30ms/step\n",
      "Epoch 20/900\n",
      "5/5 - 0s - loss: 0.3288 - val_loss: 0.3490 - 148ms/epoch - 30ms/step\n",
      "Epoch 21/900\n",
      "5/5 - 0s - loss: 0.3206 - val_loss: 0.3412 - 177ms/epoch - 35ms/step\n",
      "Epoch 22/900\n",
      "5/5 - 0s - loss: 0.3124 - val_loss: 0.3326 - 148ms/epoch - 30ms/step\n",
      "Epoch 23/900\n",
      "5/5 - 0s - loss: 0.3044 - val_loss: 0.3236 - 150ms/epoch - 30ms/step\n",
      "Epoch 24/900\n",
      "5/5 - 0s - loss: 0.2967 - val_loss: 0.3174 - 149ms/epoch - 30ms/step\n",
      "Epoch 25/900\n",
      "5/5 - 0s - loss: 0.2898 - val_loss: 0.3101 - 146ms/epoch - 29ms/step\n",
      "Epoch 26/900\n",
      "5/5 - 0s - loss: 0.2825 - val_loss: 0.3007 - 149ms/epoch - 30ms/step\n",
      "Epoch 27/900\n",
      "5/5 - 0s - loss: 0.2754 - val_loss: 0.2933 - 147ms/epoch - 29ms/step\n",
      "Epoch 28/900\n",
      "5/5 - 0s - loss: 0.2690 - val_loss: 0.2857 - 147ms/epoch - 29ms/step\n",
      "Epoch 29/900\n",
      "5/5 - 0s - loss: 0.2624 - val_loss: 0.2786 - 151ms/epoch - 30ms/step\n",
      "Epoch 30/900\n",
      "5/5 - 0s - loss: 0.2562 - val_loss: 0.2734 - 147ms/epoch - 29ms/step\n",
      "Epoch 31/900\n",
      "5/5 - 0s - loss: 0.2503 - val_loss: 0.2665 - 147ms/epoch - 29ms/step\n",
      "Epoch 32/900\n",
      "5/5 - 0s - loss: 0.2443 - val_loss: 0.2594 - 147ms/epoch - 29ms/step\n",
      "Epoch 33/900\n",
      "5/5 - 0s - loss: 0.2389 - val_loss: 0.2556 - 147ms/epoch - 29ms/step\n",
      "Epoch 34/900\n",
      "5/5 - 0s - loss: 0.2334 - val_loss: 0.2489 - 149ms/epoch - 30ms/step\n",
      "Epoch 35/900\n",
      "5/5 - 0s - loss: 0.2279 - val_loss: 0.2425 - 146ms/epoch - 29ms/step\n",
      "Epoch 36/900\n",
      "5/5 - 0s - loss: 0.2225 - val_loss: 0.2376 - 147ms/epoch - 29ms/step\n",
      "Epoch 37/900\n",
      "5/5 - 0s - loss: 0.2177 - val_loss: 0.2334 - 148ms/epoch - 30ms/step\n",
      "Epoch 38/900\n",
      "5/5 - 0s - loss: 0.2127 - val_loss: 0.2268 - 144ms/epoch - 29ms/step\n",
      "Epoch 39/900\n",
      "5/5 - 0s - loss: 0.2080 - val_loss: 0.2227 - 146ms/epoch - 29ms/step\n",
      "Epoch 40/900\n",
      "5/5 - 0s - loss: 0.2036 - val_loss: 0.2172 - 142ms/epoch - 28ms/step\n",
      "Epoch 41/900\n",
      "5/5 - 0s - loss: 0.1991 - val_loss: 0.2126 - 159ms/epoch - 32ms/step\n",
      "Epoch 42/900\n",
      "5/5 - 0s - loss: 0.1944 - val_loss: 0.2086 - 150ms/epoch - 30ms/step\n",
      "Epoch 43/900\n",
      "5/5 - 0s - loss: 0.1905 - val_loss: 0.2057 - 145ms/epoch - 29ms/step\n",
      "Epoch 44/900\n",
      "5/5 - 0s - loss: 0.1864 - val_loss: 0.2000 - 151ms/epoch - 30ms/step\n",
      "Epoch 45/900\n",
      "5/5 - 0s - loss: 0.1821 - val_loss: 0.1957 - 150ms/epoch - 30ms/step\n",
      "Epoch 46/900\n",
      "5/5 - 0s - loss: 0.1789 - val_loss: 0.1921 - 150ms/epoch - 30ms/step\n",
      "Epoch 47/900\n",
      "5/5 - 0s - loss: 0.1750 - val_loss: 0.1880 - 151ms/epoch - 30ms/step\n",
      "Epoch 48/900\n",
      "5/5 - 0s - loss: 0.1713 - val_loss: 0.1835 - 150ms/epoch - 30ms/step\n",
      "Epoch 49/900\n",
      "5/5 - 0s - loss: 0.1681 - val_loss: 0.1805 - 147ms/epoch - 29ms/step\n",
      "Epoch 50/900\n",
      "5/5 - 0s - loss: 0.1645 - val_loss: 0.1777 - 147ms/epoch - 29ms/step\n",
      "Epoch 51/900\n",
      "5/5 - 0s - loss: 0.1613 - val_loss: 0.1742 - 149ms/epoch - 30ms/step\n",
      "Epoch 52/900\n",
      "5/5 - 0s - loss: 0.1580 - val_loss: 0.1697 - 148ms/epoch - 30ms/step\n",
      "Epoch 53/900\n",
      "5/5 - 0s - loss: 0.1546 - val_loss: 0.1679 - 148ms/epoch - 30ms/step\n",
      "Epoch 54/900\n",
      "5/5 - 0s - loss: 0.1515 - val_loss: 0.1635 - 146ms/epoch - 29ms/step\n",
      "Epoch 55/900\n",
      "5/5 - 0s - loss: 0.1482 - val_loss: 0.1609 - 150ms/epoch - 30ms/step\n",
      "Epoch 56/900\n",
      "5/5 - 0s - loss: 0.1459 - val_loss: 0.1575 - 148ms/epoch - 30ms/step\n",
      "Epoch 57/900\n",
      "5/5 - 0s - loss: 0.1431 - val_loss: 0.1550 - 147ms/epoch - 29ms/step\n",
      "Epoch 58/900\n",
      "5/5 - 0s - loss: 0.1400 - val_loss: 0.1525 - 142ms/epoch - 28ms/step\n",
      "Epoch 59/900\n",
      "5/5 - 0s - loss: 0.1374 - val_loss: 0.1494 - 144ms/epoch - 29ms/step\n",
      "Epoch 60/900\n",
      "5/5 - 0s - loss: 0.1348 - val_loss: 0.1487 - 146ms/epoch - 29ms/step\n",
      "Epoch 61/900\n",
      "5/5 - 0s - loss: 0.1327 - val_loss: 0.1445 - 157ms/epoch - 31ms/step\n",
      "Epoch 62/900\n",
      "5/5 - 0s - loss: 0.1310 - val_loss: 0.1420 - 149ms/epoch - 30ms/step\n",
      "Epoch 63/900\n",
      "5/5 - 0s - loss: 0.1280 - val_loss: 0.1407 - 147ms/epoch - 29ms/step\n",
      "Epoch 64/900\n",
      "5/5 - 0s - loss: 0.1253 - val_loss: 0.1364 - 146ms/epoch - 29ms/step\n",
      "Epoch 65/900\n",
      "5/5 - 0s - loss: 0.1231 - val_loss: 0.1339 - 146ms/epoch - 29ms/step\n",
      "Epoch 66/900\n",
      "5/5 - 0s - loss: 0.1211 - val_loss: 0.1350 - 144ms/epoch - 29ms/step\n",
      "Epoch 67/900\n",
      "5/5 - 0s - loss: 0.1190 - val_loss: 0.1301 - 149ms/epoch - 30ms/step\n",
      "Epoch 68/900\n",
      "5/5 - 0s - loss: 0.1168 - val_loss: 0.1279 - 151ms/epoch - 30ms/step\n",
      "Epoch 69/900\n",
      "5/5 - 0s - loss: 0.1149 - val_loss: 0.1266 - 150ms/epoch - 30ms/step\n",
      "Epoch 70/900\n",
      "5/5 - 0s - loss: 0.1130 - val_loss: 0.1245 - 148ms/epoch - 30ms/step\n",
      "Epoch 71/900\n",
      "5/5 - 0s - loss: 0.1111 - val_loss: 0.1222 - 148ms/epoch - 30ms/step\n",
      "Epoch 72/900\n",
      "5/5 - 0s - loss: 0.1095 - val_loss: 0.1205 - 151ms/epoch - 30ms/step\n",
      "Epoch 73/900\n",
      "5/5 - 0s - loss: 0.1076 - val_loss: 0.1181 - 148ms/epoch - 30ms/step\n",
      "Epoch 74/900\n",
      "5/5 - 0s - loss: 0.1061 - val_loss: 0.1169 - 153ms/epoch - 31ms/step\n",
      "Epoch 75/900\n",
      "5/5 - 0s - loss: 0.1040 - val_loss: 0.1151 - 148ms/epoch - 30ms/step\n",
      "Epoch 76/900\n",
      "5/5 - 0s - loss: 0.1025 - val_loss: 0.1144 - 148ms/epoch - 30ms/step\n",
      "Epoch 77/900\n",
      "5/5 - 0s - loss: 0.1008 - val_loss: 0.1124 - 150ms/epoch - 30ms/step\n",
      "Epoch 78/900\n",
      "5/5 - 0s - loss: 0.0993 - val_loss: 0.1106 - 148ms/epoch - 30ms/step\n",
      "Epoch 79/900\n",
      "5/5 - 0s - loss: 0.0975 - val_loss: 0.1095 - 149ms/epoch - 30ms/step\n",
      "Epoch 80/900\n",
      "5/5 - 0s - loss: 0.0961 - val_loss: 0.1067 - 147ms/epoch - 29ms/step\n",
      "Epoch 81/900\n",
      "5/5 - 0s - loss: 0.0947 - val_loss: 0.1053 - 145ms/epoch - 29ms/step\n",
      "Epoch 82/900\n",
      "5/5 - 0s - loss: 0.0934 - val_loss: 0.1054 - 148ms/epoch - 30ms/step\n",
      "Epoch 83/900\n",
      "5/5 - 0s - loss: 0.0919 - val_loss: 0.1025 - 151ms/epoch - 30ms/step\n",
      "Epoch 84/900\n",
      "5/5 - 0s - loss: 0.0904 - val_loss: 0.1010 - 149ms/epoch - 30ms/step\n",
      "Epoch 85/900\n",
      "5/5 - 0s - loss: 0.0890 - val_loss: 0.0997 - 148ms/epoch - 30ms/step\n",
      "Epoch 86/900\n",
      "5/5 - 0s - loss: 0.0877 - val_loss: 0.0986 - 146ms/epoch - 29ms/step\n",
      "Epoch 87/900\n",
      "5/5 - 0s - loss: 0.0865 - val_loss: 0.0977 - 147ms/epoch - 29ms/step\n",
      "Epoch 88/900\n",
      "5/5 - 0s - loss: 0.0854 - val_loss: 0.0967 - 146ms/epoch - 29ms/step\n",
      "Epoch 89/900\n",
      "5/5 - 0s - loss: 0.0841 - val_loss: 0.0946 - 148ms/epoch - 30ms/step\n",
      "Epoch 90/900\n",
      "5/5 - 0s - loss: 0.0829 - val_loss: 0.0941 - 158ms/epoch - 32ms/step\n",
      "Epoch 91/900\n",
      "5/5 - 0s - loss: 0.0820 - val_loss: 0.0932 - 174ms/epoch - 35ms/step\n",
      "Epoch 92/900\n",
      "5/5 - 0s - loss: 0.0812 - val_loss: 0.0919 - 189ms/epoch - 38ms/step\n",
      "Epoch 93/900\n",
      "5/5 - 0s - loss: 0.0800 - val_loss: 0.0901 - 156ms/epoch - 31ms/step\n",
      "Epoch 94/900\n",
      "5/5 - 0s - loss: 0.0793 - val_loss: 0.0909 - 162ms/epoch - 32ms/step\n",
      "Epoch 95/900\n",
      "5/5 - 0s - loss: 0.0785 - val_loss: 0.0881 - 156ms/epoch - 31ms/step\n",
      "Epoch 96/900\n",
      "5/5 - 0s - loss: 0.0774 - val_loss: 0.0872 - 156ms/epoch - 31ms/step\n",
      "Epoch 97/900\n",
      "5/5 - 0s - loss: 0.0762 - val_loss: 0.0870 - 170ms/epoch - 34ms/step\n",
      "Epoch 98/900\n",
      "5/5 - 0s - loss: 0.0750 - val_loss: 0.0848 - 184ms/epoch - 37ms/step\n",
      "Epoch 99/900\n",
      "5/5 - 0s - loss: 0.0740 - val_loss: 0.0838 - 163ms/epoch - 33ms/step\n",
      "Epoch 100/900\n",
      "5/5 - 0s - loss: 0.0733 - val_loss: 0.0844 - 157ms/epoch - 31ms/step\n",
      "Epoch 101/900\n",
      "5/5 - 0s - loss: 0.0723 - val_loss: 0.0826 - 151ms/epoch - 30ms/step\n",
      "Epoch 102/900\n",
      "5/5 - 0s - loss: 0.0712 - val_loss: 0.0807 - 149ms/epoch - 30ms/step\n",
      "Epoch 103/900\n",
      "5/5 - 0s - loss: 0.0701 - val_loss: 0.0811 - 149ms/epoch - 30ms/step\n",
      "Epoch 104/900\n",
      "5/5 - 0s - loss: 0.0694 - val_loss: 0.0796 - 151ms/epoch - 30ms/step\n",
      "Epoch 105/900\n",
      "5/5 - 0s - loss: 0.0686 - val_loss: 0.0785 - 149ms/epoch - 30ms/step\n",
      "Epoch 106/900\n",
      "5/5 - 0s - loss: 0.0677 - val_loss: 0.0775 - 148ms/epoch - 30ms/step\n",
      "Epoch 107/900\n",
      "5/5 - 0s - loss: 0.0669 - val_loss: 0.0772 - 149ms/epoch - 30ms/step\n",
      "Epoch 108/900\n",
      "5/5 - 0s - loss: 0.0662 - val_loss: 0.0760 - 148ms/epoch - 30ms/step\n",
      "Epoch 109/900\n",
      "5/5 - 0s - loss: 0.0654 - val_loss: 0.0755 - 149ms/epoch - 30ms/step\n",
      "Epoch 110/900\n",
      "5/5 - 0s - loss: 0.0650 - val_loss: 0.0743 - 145ms/epoch - 29ms/step\n",
      "Epoch 111/900\n",
      "5/5 - 0s - loss: 0.0645 - val_loss: 0.0739 - 147ms/epoch - 29ms/step\n",
      "Epoch 112/900\n",
      "5/5 - 0s - loss: 0.0637 - val_loss: 0.0725 - 148ms/epoch - 30ms/step\n",
      "Epoch 113/900\n",
      "5/5 - 0s - loss: 0.0627 - val_loss: 0.0728 - 149ms/epoch - 30ms/step\n",
      "Epoch 114/900\n",
      "5/5 - 0s - loss: 0.0621 - val_loss: 0.0731 - 147ms/epoch - 29ms/step\n",
      "Epoch 115/900\n",
      "5/5 - 0s - loss: 0.0619 - val_loss: 0.0712 - 144ms/epoch - 29ms/step\n",
      "Epoch 116/900\n",
      "5/5 - 0s - loss: 0.0608 - val_loss: 0.0704 - 146ms/epoch - 29ms/step\n",
      "Epoch 117/900\n",
      "5/5 - 0s - loss: 0.0600 - val_loss: 0.0693 - 186ms/epoch - 37ms/step\n",
      "Epoch 118/900\n",
      "5/5 - 0s - loss: 0.0594 - val_loss: 0.0685 - 144ms/epoch - 29ms/step\n",
      "Epoch 119/900\n",
      "5/5 - 0s - loss: 0.0587 - val_loss: 0.0683 - 146ms/epoch - 29ms/step\n",
      "Epoch 120/900\n",
      "5/5 - 0s - loss: 0.0580 - val_loss: 0.0673 - 159ms/epoch - 32ms/step\n",
      "Epoch 121/900\n",
      "5/5 - 0s - loss: 0.0575 - val_loss: 0.0672 - 147ms/epoch - 29ms/step\n",
      "Epoch 122/900\n",
      "5/5 - 0s - loss: 0.0571 - val_loss: 0.0663 - 144ms/epoch - 29ms/step\n",
      "Epoch 123/900\n",
      "5/5 - 0s - loss: 0.0564 - val_loss: 0.0658 - 147ms/epoch - 29ms/step\n",
      "Epoch 124/900\n",
      "5/5 - 0s - loss: 0.0559 - val_loss: 0.0650 - 151ms/epoch - 30ms/step\n",
      "Epoch 125/900\n",
      "5/5 - 0s - loss: 0.0555 - val_loss: 0.0653 - 151ms/epoch - 30ms/step\n",
      "Epoch 126/900\n",
      "5/5 - 0s - loss: 0.0551 - val_loss: 0.0651 - 151ms/epoch - 30ms/step\n",
      "Epoch 127/900\n",
      "5/5 - 0s - loss: 0.0546 - val_loss: 0.0634 - 154ms/epoch - 31ms/step\n",
      "Epoch 128/900\n",
      "5/5 - 0s - loss: 0.0537 - val_loss: 0.0628 - 150ms/epoch - 30ms/step\n",
      "Epoch 129/900\n",
      "5/5 - 0s - loss: 0.0532 - val_loss: 0.0620 - 152ms/epoch - 30ms/step\n",
      "Epoch 130/900\n",
      "5/5 - 0s - loss: 0.0526 - val_loss: 0.0622 - 147ms/epoch - 29ms/step\n",
      "Epoch 131/900\n",
      "5/5 - 0s - loss: 0.0522 - val_loss: 0.0612 - 149ms/epoch - 30ms/step\n",
      "Epoch 132/900\n",
      "5/5 - 0s - loss: 0.0516 - val_loss: 0.0612 - 156ms/epoch - 31ms/step\n",
      "Epoch 133/900\n",
      "5/5 - 0s - loss: 0.0513 - val_loss: 0.0621 - 146ms/epoch - 29ms/step\n",
      "Epoch 134/900\n",
      "5/5 - 0s - loss: 0.0512 - val_loss: 0.0597 - 146ms/epoch - 29ms/step\n",
      "Epoch 135/900\n",
      "5/5 - 0s - loss: 0.0505 - val_loss: 0.0606 - 148ms/epoch - 30ms/step\n",
      "Epoch 136/900\n",
      "5/5 - 0s - loss: 0.0507 - val_loss: 0.0598 - 149ms/epoch - 30ms/step\n",
      "Epoch 137/900\n",
      "5/5 - 0s - loss: 0.0500 - val_loss: 0.0583 - 148ms/epoch - 30ms/step\n",
      "Epoch 138/900\n",
      "5/5 - 0s - loss: 0.0492 - val_loss: 0.0579 - 147ms/epoch - 29ms/step\n",
      "Epoch 139/900\n",
      "5/5 - 0s - loss: 0.0487 - val_loss: 0.0572 - 145ms/epoch - 29ms/step\n",
      "Epoch 140/900\n",
      "5/5 - 0s - loss: 0.0481 - val_loss: 0.0576 - 145ms/epoch - 29ms/step\n",
      "Epoch 141/900\n",
      "5/5 - 0s - loss: 0.0478 - val_loss: 0.0563 - 146ms/epoch - 29ms/step\n",
      "Epoch 142/900\n",
      "5/5 - 0s - loss: 0.0477 - val_loss: 0.0564 - 153ms/epoch - 31ms/step\n",
      "Epoch 143/900\n",
      "5/5 - 0s - loss: 0.0475 - val_loss: 0.0559 - 150ms/epoch - 30ms/step\n",
      "Epoch 144/900\n",
      "5/5 - 0s - loss: 0.0469 - val_loss: 0.0556 - 148ms/epoch - 30ms/step\n",
      "Epoch 145/900\n",
      "5/5 - 0s - loss: 0.0464 - val_loss: 0.0553 - 155ms/epoch - 31ms/step\n",
      "Epoch 146/900\n",
      "5/5 - 0s - loss: 0.0462 - val_loss: 0.0544 - 147ms/epoch - 29ms/step\n",
      "Epoch 147/900\n",
      "5/5 - 0s - loss: 0.0456 - val_loss: 0.0544 - 148ms/epoch - 30ms/step\n",
      "Epoch 148/900\n",
      "5/5 - 0s - loss: 0.0453 - val_loss: 0.0551 - 143ms/epoch - 29ms/step\n",
      "Epoch 149/900\n",
      "5/5 - 0s - loss: 0.0455 - val_loss: 0.0534 - 143ms/epoch - 29ms/step\n",
      "Epoch 150/900\n",
      "5/5 - 0s - loss: 0.0456 - val_loss: 0.0544 - 150ms/epoch - 30ms/step\n",
      "Epoch 151/900\n",
      "5/5 - 0s - loss: 0.0449 - val_loss: 0.0524 - 156ms/epoch - 31ms/step\n",
      "Epoch 152/900\n",
      "5/5 - 0s - loss: 0.0447 - val_loss: 0.0557 - 151ms/epoch - 30ms/step\n",
      "Epoch 153/900\n",
      "5/5 - 0s - loss: 0.0452 - val_loss: 0.0528 - 150ms/epoch - 30ms/step\n",
      "Epoch 154/900\n",
      "5/5 - 0s - loss: 0.0439 - val_loss: 0.0523 - 154ms/epoch - 31ms/step\n",
      "Epoch 155/900\n",
      "5/5 - 0s - loss: 0.0432 - val_loss: 0.0526 - 145ms/epoch - 29ms/step\n",
      "Epoch 156/900\n",
      "5/5 - 0s - loss: 0.0429 - val_loss: 0.0509 - 148ms/epoch - 30ms/step\n",
      "Epoch 157/900\n",
      "5/5 - 0s - loss: 0.0425 - val_loss: 0.0506 - 148ms/epoch - 30ms/step\n",
      "Epoch 158/900\n",
      "5/5 - 0s - loss: 0.0422 - val_loss: 0.0498 - 151ms/epoch - 30ms/step\n",
      "Epoch 159/900\n",
      "5/5 - 0s - loss: 0.0417 - val_loss: 0.0531 - 148ms/epoch - 30ms/step\n",
      "Epoch 160/900\n",
      "5/5 - 0s - loss: 0.0421 - val_loss: 0.0494 - 150ms/epoch - 30ms/step\n",
      "Epoch 161/900\n",
      "5/5 - 0s - loss: 0.0415 - val_loss: 0.0495 - 147ms/epoch - 29ms/step\n",
      "Epoch 162/900\n",
      "5/5 - 0s - loss: 0.0409 - val_loss: 0.0490 - 149ms/epoch - 30ms/step\n",
      "Epoch 163/900\n",
      "5/5 - 0s - loss: 0.0407 - val_loss: 0.0494 - 150ms/epoch - 30ms/step\n",
      "Epoch 164/900\n",
      "5/5 - 0s - loss: 0.0406 - val_loss: 0.0490 - 149ms/epoch - 30ms/step\n",
      "Epoch 165/900\n",
      "5/5 - 0s - loss: 0.0404 - val_loss: 0.0481 - 148ms/epoch - 30ms/step\n",
      "Epoch 166/900\n",
      "5/5 - 0s - loss: 0.0399 - val_loss: 0.0489 - 150ms/epoch - 30ms/step\n",
      "Epoch 167/900\n",
      "5/5 - 0s - loss: 0.0400 - val_loss: 0.0477 - 149ms/epoch - 30ms/step\n",
      "Epoch 168/900\n",
      "5/5 - 0s - loss: 0.0395 - val_loss: 0.0483 - 145ms/epoch - 29ms/step\n",
      "Epoch 169/900\n",
      "5/5 - 0s - loss: 0.0392 - val_loss: 0.0473 - 149ms/epoch - 30ms/step\n",
      "Epoch 170/900\n",
      "5/5 - 0s - loss: 0.0387 - val_loss: 0.0469 - 148ms/epoch - 30ms/step\n",
      "Epoch 171/900\n",
      "5/5 - 0s - loss: 0.0385 - val_loss: 0.0464 - 149ms/epoch - 30ms/step\n",
      "Epoch 172/900\n",
      "5/5 - 0s - loss: 0.0383 - val_loss: 0.0461 - 151ms/epoch - 30ms/step\n",
      "Epoch 173/900\n",
      "5/5 - 0s - loss: 0.0379 - val_loss: 0.0461 - 160ms/epoch - 32ms/step\n",
      "Epoch 174/900\n",
      "5/5 - 0s - loss: 0.0377 - val_loss: 0.0459 - 156ms/epoch - 31ms/step\n",
      "Epoch 175/900\n",
      "5/5 - 0s - loss: 0.0378 - val_loss: 0.0454 - 187ms/epoch - 37ms/step\n",
      "Epoch 176/900\n",
      "5/5 - 0s - loss: 0.0374 - val_loss: 0.0452 - 163ms/epoch - 33ms/step\n",
      "Epoch 177/900\n",
      "5/5 - 0s - loss: 0.0373 - val_loss: 0.0451 - 159ms/epoch - 32ms/step\n",
      "Epoch 178/900\n",
      "5/5 - 0s - loss: 0.0369 - val_loss: 0.0447 - 155ms/epoch - 31ms/step\n",
      "Epoch 179/900\n",
      "5/5 - 0s - loss: 0.0368 - val_loss: 0.0444 - 163ms/epoch - 33ms/step\n",
      "Epoch 180/900\n",
      "5/5 - 0s - loss: 0.0364 - val_loss: 0.0447 - 195ms/epoch - 39ms/step\n",
      "Epoch 181/900\n",
      "5/5 - 0s - loss: 0.0364 - val_loss: 0.0438 - 171ms/epoch - 34ms/step\n",
      "Epoch 182/900\n",
      "5/5 - 0s - loss: 0.0358 - val_loss: 0.0436 - 161ms/epoch - 32ms/step\n",
      "Epoch 183/900\n",
      "5/5 - 0s - loss: 0.0358 - val_loss: 0.0436 - 148ms/epoch - 30ms/step\n",
      "Epoch 184/900\n",
      "5/5 - 0s - loss: 0.0358 - val_loss: 0.0436 - 160ms/epoch - 32ms/step\n",
      "Epoch 185/900\n",
      "5/5 - 0s - loss: 0.0356 - val_loss: 0.0429 - 190ms/epoch - 38ms/step\n",
      "Epoch 186/900\n",
      "5/5 - 0s - loss: 0.0351 - val_loss: 0.0433 - 171ms/epoch - 34ms/step\n",
      "Epoch 187/900\n",
      "5/5 - 0s - loss: 0.0350 - val_loss: 0.0424 - 151ms/epoch - 30ms/step\n",
      "Epoch 188/900\n",
      "5/5 - 0s - loss: 0.0348 - val_loss: 0.0424 - 146ms/epoch - 29ms/step\n",
      "Epoch 189/900\n",
      "5/5 - 0s - loss: 0.0345 - val_loss: 0.0423 - 147ms/epoch - 29ms/step\n",
      "Epoch 190/900\n",
      "5/5 - 0s - loss: 0.0345 - val_loss: 0.0418 - 150ms/epoch - 30ms/step\n",
      "Epoch 191/900\n",
      "5/5 - 0s - loss: 0.0342 - val_loss: 0.0421 - 146ms/epoch - 29ms/step\n",
      "Epoch 192/900\n",
      "5/5 - 0s - loss: 0.0340 - val_loss: 0.0414 - 146ms/epoch - 29ms/step\n",
      "Epoch 193/900\n",
      "5/5 - 0s - loss: 0.0338 - val_loss: 0.0415 - 151ms/epoch - 30ms/step\n",
      "Epoch 194/900\n",
      "5/5 - 0s - loss: 0.0336 - val_loss: 0.0412 - 146ms/epoch - 29ms/step\n",
      "Epoch 195/900\n",
      "5/5 - 0s - loss: 0.0336 - val_loss: 0.0413 - 144ms/epoch - 29ms/step\n",
      "Epoch 196/900\n",
      "5/5 - 0s - loss: 0.0334 - val_loss: 0.0408 - 148ms/epoch - 30ms/step\n",
      "Epoch 197/900\n",
      "5/5 - 0s - loss: 0.0331 - val_loss: 0.0406 - 148ms/epoch - 30ms/step\n",
      "Epoch 198/900\n",
      "5/5 - 0s - loss: 0.0330 - val_loss: 0.0415 - 146ms/epoch - 29ms/step\n",
      "Epoch 199/900\n",
      "5/5 - 0s - loss: 0.0329 - val_loss: 0.0400 - 143ms/epoch - 29ms/step\n",
      "Epoch 200/900\n",
      "5/5 - 0s - loss: 0.0329 - val_loss: 0.0402 - 145ms/epoch - 29ms/step\n",
      "Epoch 201/900\n",
      "5/5 - 0s - loss: 0.0324 - val_loss: 0.0400 - 146ms/epoch - 29ms/step\n",
      "Epoch 202/900\n",
      "5/5 - 0s - loss: 0.0323 - val_loss: 0.0398 - 142ms/epoch - 28ms/step\n",
      "Epoch 203/900\n",
      "5/5 - 0s - loss: 0.0321 - val_loss: 0.0403 - 148ms/epoch - 30ms/step\n",
      "Epoch 204/900\n",
      "5/5 - 0s - loss: 0.0323 - val_loss: 0.0398 - 151ms/epoch - 30ms/step\n",
      "Epoch 205/900\n",
      "5/5 - 0s - loss: 0.0322 - val_loss: 0.0395 - 153ms/epoch - 31ms/step\n",
      "Epoch 206/900\n",
      "5/5 - 0s - loss: 0.0316 - val_loss: 0.0394 - 152ms/epoch - 30ms/step\n",
      "Epoch 207/900\n",
      "5/5 - 0s - loss: 0.0316 - val_loss: 0.0388 - 152ms/epoch - 30ms/step\n",
      "Epoch 208/900\n",
      "5/5 - 0s - loss: 0.0313 - val_loss: 0.0388 - 148ms/epoch - 30ms/step\n",
      "Epoch 209/900\n",
      "5/5 - 0s - loss: 0.0312 - val_loss: 0.0384 - 147ms/epoch - 29ms/step\n",
      "Epoch 210/900\n",
      "5/5 - 0s - loss: 0.0311 - val_loss: 0.0382 - 151ms/epoch - 30ms/step\n",
      "Epoch 211/900\n",
      "5/5 - 0s - loss: 0.0308 - val_loss: 0.0381 - 148ms/epoch - 30ms/step\n",
      "Epoch 212/900\n",
      "5/5 - 0s - loss: 0.0307 - val_loss: 0.0380 - 156ms/epoch - 31ms/step\n",
      "Epoch 213/900\n",
      "5/5 - 0s - loss: 0.0305 - val_loss: 0.0379 - 149ms/epoch - 30ms/step\n",
      "Epoch 214/900\n",
      "5/5 - 0s - loss: 0.0303 - val_loss: 0.0375 - 145ms/epoch - 29ms/step\n",
      "Epoch 215/900\n",
      "5/5 - 0s - loss: 0.0301 - val_loss: 0.0376 - 147ms/epoch - 29ms/step\n",
      "Epoch 216/900\n",
      "5/5 - 0s - loss: 0.0300 - val_loss: 0.0379 - 149ms/epoch - 30ms/step\n",
      "Epoch 217/900\n",
      "5/5 - 0s - loss: 0.0301 - val_loss: 0.0371 - 151ms/epoch - 30ms/step\n",
      "Epoch 218/900\n",
      "5/5 - 0s - loss: 0.0298 - val_loss: 0.0371 - 150ms/epoch - 30ms/step\n",
      "Epoch 219/900\n",
      "5/5 - 0s - loss: 0.0298 - val_loss: 0.0370 - 148ms/epoch - 30ms/step\n",
      "Epoch 220/900\n",
      "5/5 - 0s - loss: 0.0296 - val_loss: 0.0370 - 145ms/epoch - 29ms/step\n",
      "Epoch 221/900\n",
      "5/5 - 0s - loss: 0.0294 - val_loss: 0.0369 - 146ms/epoch - 29ms/step\n",
      "Epoch 222/900\n",
      "5/5 - 0s - loss: 0.0294 - val_loss: 0.0369 - 147ms/epoch - 29ms/step\n",
      "Epoch 223/900\n",
      "5/5 - 0s - loss: 0.0293 - val_loss: 0.0371 - 144ms/epoch - 29ms/step\n",
      "Epoch 224/900\n",
      "5/5 - 0s - loss: 0.0295 - val_loss: 0.0377 - 146ms/epoch - 29ms/step\n",
      "Epoch 225/900\n",
      "5/5 - 0s - loss: 0.0294 - val_loss: 0.0360 - 147ms/epoch - 29ms/step\n",
      "Epoch 226/900\n",
      "5/5 - 0s - loss: 0.0289 - val_loss: 0.0361 - 148ms/epoch - 30ms/step\n",
      "Epoch 227/900\n",
      "5/5 - 0s - loss: 0.0288 - val_loss: 0.0358 - 146ms/epoch - 29ms/step\n",
      "Epoch 228/900\n",
      "5/5 - 0s - loss: 0.0286 - val_loss: 0.0355 - 149ms/epoch - 30ms/step\n",
      "Epoch 229/900\n",
      "5/5 - 0s - loss: 0.0284 - val_loss: 0.0358 - 153ms/epoch - 31ms/step\n",
      "Epoch 230/900\n",
      "5/5 - 0s - loss: 0.0283 - val_loss: 0.0354 - 165ms/epoch - 33ms/step\n",
      "Epoch 231/900\n",
      "5/5 - 0s - loss: 0.0281 - val_loss: 0.0352 - 165ms/epoch - 33ms/step\n",
      "Epoch 232/900\n",
      "5/5 - 0s - loss: 0.0280 - val_loss: 0.0352 - 165ms/epoch - 33ms/step\n",
      "Epoch 233/900\n",
      "5/5 - 0s - loss: 0.0282 - val_loss: 0.0350 - 167ms/epoch - 33ms/step\n",
      "Epoch 234/900\n",
      "5/5 - 0s - loss: 0.0279 - val_loss: 0.0353 - 164ms/epoch - 33ms/step\n",
      "Epoch 235/900\n",
      "5/5 - 0s - loss: 0.0280 - val_loss: 0.0361 - 164ms/epoch - 33ms/step\n",
      "Epoch 236/900\n",
      "5/5 - 0s - loss: 0.0282 - val_loss: 0.0347 - 166ms/epoch - 33ms/step\n",
      "Epoch 237/900\n",
      "5/5 - 0s - loss: 0.0278 - val_loss: 0.0355 - 161ms/epoch - 32ms/step\n",
      "Epoch 238/900\n",
      "5/5 - 0s - loss: 0.0279 - val_loss: 0.0345 - 167ms/epoch - 33ms/step\n",
      "Epoch 239/900\n",
      "5/5 - 0s - loss: 0.0275 - val_loss: 0.0344 - 164ms/epoch - 33ms/step\n",
      "Epoch 240/900\n",
      "5/5 - 0s - loss: 0.0273 - val_loss: 0.0346 - 172ms/epoch - 34ms/step\n",
      "Epoch 241/900\n",
      "5/5 - 0s - loss: 0.0271 - val_loss: 0.0342 - 185ms/epoch - 37ms/step\n",
      "Epoch 242/900\n",
      "5/5 - 0s - loss: 0.0272 - val_loss: 0.0358 - 162ms/epoch - 32ms/step\n",
      "Epoch 243/900\n",
      "5/5 - 0s - loss: 0.0275 - val_loss: 0.0338 - 165ms/epoch - 33ms/step\n",
      "Epoch 244/900\n",
      "5/5 - 0s - loss: 0.0270 - val_loss: 0.0349 - 163ms/epoch - 33ms/step\n",
      "Epoch 245/900\n",
      "5/5 - 0s - loss: 0.0269 - val_loss: 0.0346 - 161ms/epoch - 32ms/step\n",
      "Epoch 246/900\n",
      "5/5 - 0s - loss: 0.0270 - val_loss: 0.0337 - 164ms/epoch - 33ms/step\n",
      "Epoch 247/900\n",
      "5/5 - 0s - loss: 0.0266 - val_loss: 0.0334 - 174ms/epoch - 35ms/step\n",
      "Epoch 248/900\n",
      "5/5 - 0s - loss: 0.0264 - val_loss: 0.0333 - 193ms/epoch - 39ms/step\n",
      "Epoch 249/900\n",
      "5/5 - 0s - loss: 0.0263 - val_loss: 0.0336 - 187ms/epoch - 37ms/step\n",
      "Epoch 250/900\n",
      "5/5 - 0s - loss: 0.0264 - val_loss: 0.0333 - 180ms/epoch - 36ms/step\n",
      "Epoch 251/900\n",
      "5/5 - 0s - loss: 0.0262 - val_loss: 0.0331 - 169ms/epoch - 34ms/step\n",
      "Epoch 252/900\n",
      "5/5 - 0s - loss: 0.0261 - val_loss: 0.0329 - 168ms/epoch - 34ms/step\n",
      "Epoch 253/900\n",
      "5/5 - 0s - loss: 0.0259 - val_loss: 0.0331 - 170ms/epoch - 34ms/step\n",
      "Epoch 254/900\n",
      "5/5 - 0s - loss: 0.0258 - val_loss: 0.0327 - 172ms/epoch - 34ms/step\n",
      "Epoch 255/900\n",
      "5/5 - 0s - loss: 0.0257 - val_loss: 0.0329 - 164ms/epoch - 33ms/step\n",
      "Epoch 256/900\n",
      "5/5 - 0s - loss: 0.0257 - val_loss: 0.0328 - 159ms/epoch - 32ms/step\n",
      "Epoch 257/900\n",
      "5/5 - 0s - loss: 0.0256 - val_loss: 0.0331 - 165ms/epoch - 33ms/step\n",
      "Epoch 258/900\n",
      "5/5 - 0s - loss: 0.0260 - val_loss: 0.0322 - 172ms/epoch - 34ms/step\n",
      "Epoch 259/900\n",
      "5/5 - 0s - loss: 0.0257 - val_loss: 0.0324 - 170ms/epoch - 34ms/step\n",
      "Epoch 260/900\n",
      "5/5 - 0s - loss: 0.0258 - val_loss: 0.0321 - 165ms/epoch - 33ms/step\n",
      "Epoch 261/900\n",
      "5/5 - 0s - loss: 0.0261 - val_loss: 0.0337 - 169ms/epoch - 34ms/step\n",
      "Epoch 262/900\n",
      "5/5 - 0s - loss: 0.0260 - val_loss: 0.0323 - 173ms/epoch - 35ms/step\n",
      "Epoch 263/900\n",
      "5/5 - 0s - loss: 0.0253 - val_loss: 0.0329 - 174ms/epoch - 35ms/step\n",
      "Epoch 264/900\n",
      "5/5 - 0s - loss: 0.0252 - val_loss: 0.0318 - 169ms/epoch - 34ms/step\n",
      "Epoch 265/900\n",
      "5/5 - 0s - loss: 0.0250 - val_loss: 0.0319 - 164ms/epoch - 33ms/step\n",
      "Epoch 266/900\n",
      "5/5 - 0s - loss: 0.0249 - val_loss: 0.0321 - 163ms/epoch - 33ms/step\n",
      "Epoch 267/900\n",
      "5/5 - 0s - loss: 0.0249 - val_loss: 0.0319 - 166ms/epoch - 33ms/step\n",
      "Epoch 268/900\n",
      "5/5 - 0s - loss: 0.0248 - val_loss: 0.0316 - 173ms/epoch - 35ms/step\n",
      "Epoch 269/900\n",
      "5/5 - 0s - loss: 0.0248 - val_loss: 0.0315 - 182ms/epoch - 36ms/step\n",
      "Epoch 270/900\n",
      "5/5 - 0s - loss: 0.0247 - val_loss: 0.0323 - 213ms/epoch - 43ms/step\n",
      "Epoch 271/900\n",
      "5/5 - 0s - loss: 0.0248 - val_loss: 0.0313 - 171ms/epoch - 34ms/step\n",
      "Epoch 272/900\n",
      "5/5 - 0s - loss: 0.0246 - val_loss: 0.0315 - 156ms/epoch - 31ms/step\n",
      "Epoch 273/900\n",
      "5/5 - 0s - loss: 0.0245 - val_loss: 0.0310 - 160ms/epoch - 32ms/step\n",
      "Epoch 274/900\n",
      "5/5 - 0s - loss: 0.0243 - val_loss: 0.0311 - 164ms/epoch - 33ms/step\n",
      "Epoch 275/900\n",
      "5/5 - 0s - loss: 0.0242 - val_loss: 0.0314 - 160ms/epoch - 32ms/step\n",
      "Epoch 276/900\n",
      "5/5 - 0s - loss: 0.0242 - val_loss: 0.0310 - 165ms/epoch - 33ms/step\n",
      "Epoch 277/900\n",
      "5/5 - 0s - loss: 0.0242 - val_loss: 0.0310 - 173ms/epoch - 35ms/step\n",
      "Epoch 278/900\n",
      "5/5 - 0s - loss: 0.0240 - val_loss: 0.0307 - 171ms/epoch - 34ms/step\n",
      "Epoch 279/900\n",
      "5/5 - 0s - loss: 0.0239 - val_loss: 0.0314 - 175ms/epoch - 35ms/step\n",
      "Epoch 280/900\n",
      "5/5 - 0s - loss: 0.0243 - val_loss: 0.0310 - 169ms/epoch - 34ms/step\n",
      "Epoch 281/900\n",
      "5/5 - 0s - loss: 0.0243 - val_loss: 0.0306 - 168ms/epoch - 34ms/step\n",
      "Epoch 282/900\n",
      "5/5 - 0s - loss: 0.0242 - val_loss: 0.0330 - 167ms/epoch - 33ms/step\n",
      "Epoch 283/900\n",
      "5/5 - 0s - loss: 0.0244 - val_loss: 0.0307 - 198ms/epoch - 40ms/step\n",
      "Epoch 284/900\n",
      "5/5 - 0s - loss: 0.0243 - val_loss: 0.0310 - 165ms/epoch - 33ms/step\n",
      "Epoch 285/900\n",
      "5/5 - 0s - loss: 0.0242 - val_loss: 0.0315 - 166ms/epoch - 33ms/step\n",
      "Epoch 286/900\n",
      "5/5 - 0s - loss: 0.0239 - val_loss: 0.0303 - 165ms/epoch - 33ms/step\n",
      "Epoch 287/900\n",
      "5/5 - 0s - loss: 0.0236 - val_loss: 0.0305 - 167ms/epoch - 33ms/step\n",
      "Epoch 288/900\n",
      "5/5 - 0s - loss: 0.0236 - val_loss: 0.0302 - 160ms/epoch - 32ms/step\n",
      "Epoch 289/900\n",
      "5/5 - 0s - loss: 0.0237 - val_loss: 0.0310 - 156ms/epoch - 31ms/step\n",
      "Epoch 290/900\n",
      "5/5 - 0s - loss: 0.0236 - val_loss: 0.0302 - 155ms/epoch - 31ms/step\n",
      "Epoch 291/900\n",
      "5/5 - 0s - loss: 0.0234 - val_loss: 0.0300 - 154ms/epoch - 31ms/step\n",
      "Epoch 292/900\n",
      "5/5 - 0s - loss: 0.0234 - val_loss: 0.0306 - 164ms/epoch - 33ms/step\n",
      "Epoch 293/900\n",
      "5/5 - 0s - loss: 0.0236 - val_loss: 0.0302 - 162ms/epoch - 32ms/step\n",
      "Epoch 294/900\n",
      "5/5 - 0s - loss: 0.0239 - val_loss: 0.0338 - 153ms/epoch - 31ms/step\n",
      "Epoch 295/900\n",
      "5/5 - 0s - loss: 0.0243 - val_loss: 0.0297 - 155ms/epoch - 31ms/step\n",
      "Epoch 296/900\n",
      "5/5 - 0s - loss: 0.0235 - val_loss: 0.0336 - 156ms/epoch - 31ms/step\n",
      "Epoch 297/900\n",
      "5/5 - 0s - loss: 0.0244 - val_loss: 0.0297 - 153ms/epoch - 31ms/step\n",
      "Epoch 298/900\n",
      "5/5 - 0s - loss: 0.0238 - val_loss: 0.0304 - 154ms/epoch - 31ms/step\n",
      "Epoch 299/900\n",
      "5/5 - 0s - loss: 0.0232 - val_loss: 0.0295 - 155ms/epoch - 31ms/step\n",
      "Epoch 300/900\n",
      "5/5 - 0s - loss: 0.0231 - val_loss: 0.0309 - 155ms/epoch - 31ms/step\n",
      "Epoch 301/900\n",
      "5/5 - 0s - loss: 0.0234 - val_loss: 0.0294 - 161ms/epoch - 32ms/step\n",
      "Epoch 302/900\n",
      "5/5 - 0s - loss: 0.0231 - val_loss: 0.0294 - 160ms/epoch - 32ms/step\n",
      "Epoch 303/900\n",
      "5/5 - 0s - loss: 0.0228 - val_loss: 0.0297 - 158ms/epoch - 32ms/step\n",
      "Epoch 304/900\n",
      "5/5 - 0s - loss: 0.0228 - val_loss: 0.0299 - 157ms/epoch - 31ms/step\n",
      "Epoch 305/900\n",
      "5/5 - 0s - loss: 0.0229 - val_loss: 0.0295 - 160ms/epoch - 32ms/step\n",
      "Epoch 306/900\n",
      "5/5 - 0s - loss: 0.0227 - val_loss: 0.0293 - 158ms/epoch - 32ms/step\n",
      "Epoch 307/900\n",
      "5/5 - 0s - loss: 0.0225 - val_loss: 0.0292 - 156ms/epoch - 31ms/step\n",
      "Epoch 308/900\n",
      "5/5 - 0s - loss: 0.0225 - val_loss: 0.0293 - 159ms/epoch - 32ms/step\n",
      "Epoch 309/900\n",
      "5/5 - 0s - loss: 0.0224 - val_loss: 0.0292 - 154ms/epoch - 31ms/step\n",
      "Epoch 310/900\n",
      "5/5 - 0s - loss: 0.0223 - val_loss: 0.0289 - 158ms/epoch - 32ms/step\n",
      "Epoch 311/900\n",
      "5/5 - 0s - loss: 0.0224 - val_loss: 0.0290 - 158ms/epoch - 32ms/step\n",
      "Epoch 312/900\n",
      "5/5 - 0s - loss: 0.0222 - val_loss: 0.0290 - 153ms/epoch - 31ms/step\n",
      "Epoch 313/900\n",
      "5/5 - 0s - loss: 0.0223 - val_loss: 0.0292 - 155ms/epoch - 31ms/step\n",
      "Epoch 314/900\n",
      "5/5 - 0s - loss: 0.0223 - val_loss: 0.0289 - 157ms/epoch - 31ms/step\n",
      "Epoch 315/900\n",
      "5/5 - 0s - loss: 0.0221 - val_loss: 0.0288 - 155ms/epoch - 31ms/step\n",
      "Epoch 316/900\n",
      "5/5 - 0s - loss: 0.0223 - val_loss: 0.0298 - 154ms/epoch - 31ms/step\n",
      "Epoch 317/900\n",
      "5/5 - 0s - loss: 0.0223 - val_loss: 0.0288 - 156ms/epoch - 31ms/step\n",
      "Epoch 318/900\n",
      "5/5 - 0s - loss: 0.0221 - val_loss: 0.0290 - 153ms/epoch - 31ms/step\n",
      "Epoch 319/900\n",
      "5/5 - 0s - loss: 0.0221 - val_loss: 0.0288 - 155ms/epoch - 31ms/step\n",
      "Epoch 320/900\n",
      "5/5 - 0s - loss: 0.0220 - val_loss: 0.0289 - 156ms/epoch - 31ms/step\n",
      "Epoch 321/900\n",
      "5/5 - 0s - loss: 0.0220 - val_loss: 0.0285 - 156ms/epoch - 31ms/step\n",
      "Epoch 322/900\n",
      "5/5 - 0s - loss: 0.0219 - val_loss: 0.0286 - 156ms/epoch - 31ms/step\n",
      "Epoch 323/900\n",
      "5/5 - 0s - loss: 0.0220 - val_loss: 0.0284 - 156ms/epoch - 31ms/step\n",
      "Epoch 324/900\n",
      "5/5 - 0s - loss: 0.0221 - val_loss: 0.0285 - 154ms/epoch - 31ms/step\n",
      "Epoch 325/900\n",
      "5/5 - 0s - loss: 0.0221 - val_loss: 0.0309 - 152ms/epoch - 30ms/step\n",
      "Epoch 326/900\n",
      "5/5 - 0s - loss: 0.0224 - val_loss: 0.0282 - 155ms/epoch - 31ms/step\n",
      "Epoch 327/900\n",
      "5/5 - 0s - loss: 0.0217 - val_loss: 0.0294 - 157ms/epoch - 31ms/step\n",
      "Epoch 328/900\n",
      "5/5 - 0s - loss: 0.0221 - val_loss: 0.0286 - 157ms/epoch - 31ms/step\n",
      "Epoch 329/900\n",
      "5/5 - 0s - loss: 0.0218 - val_loss: 0.0282 - 156ms/epoch - 31ms/step\n",
      "Epoch 330/900\n",
      "5/5 - 0s - loss: 0.0220 - val_loss: 0.0289 - 156ms/epoch - 31ms/step\n",
      "Epoch 331/900\n",
      "5/5 - 0s - loss: 0.0218 - val_loss: 0.0283 - 153ms/epoch - 31ms/step\n",
      "Epoch 332/900\n",
      "5/5 - 0s - loss: 0.0216 - val_loss: 0.0282 - 154ms/epoch - 31ms/step\n",
      "Epoch 333/900\n",
      "5/5 - 0s - loss: 0.0216 - val_loss: 0.0289 - 155ms/epoch - 31ms/step\n",
      "Epoch 334/900\n",
      "5/5 - 0s - loss: 0.0218 - val_loss: 0.0280 - 155ms/epoch - 31ms/step\n",
      "Epoch 335/900\n",
      "5/5 - 0s - loss: 0.0219 - val_loss: 0.0305 - 155ms/epoch - 31ms/step\n",
      "Epoch 336/900\n",
      "5/5 - 0s - loss: 0.0228 - val_loss: 0.0291 - 155ms/epoch - 31ms/step\n",
      "Epoch 337/900\n",
      "5/5 - 0s - loss: 0.0224 - val_loss: 0.0282 - 158ms/epoch - 32ms/step\n",
      "Epoch 338/900\n",
      "5/5 - 0s - loss: 0.0215 - val_loss: 0.0280 - 152ms/epoch - 30ms/step\n",
      "Epoch 339/900\n",
      "5/5 - 0s - loss: 0.0214 - val_loss: 0.0280 - 152ms/epoch - 30ms/step\n",
      "Epoch 340/900\n",
      "5/5 - 0s - loss: 0.0216 - val_loss: 0.0283 - 157ms/epoch - 31ms/step\n",
      "Epoch 341/900\n",
      "5/5 - 0s - loss: 0.0215 - val_loss: 0.0278 - 156ms/epoch - 31ms/step\n",
      "Epoch 342/900\n",
      "5/5 - 0s - loss: 0.0213 - val_loss: 0.0287 - 154ms/epoch - 31ms/step\n",
      "Epoch 343/900\n",
      "5/5 - 0s - loss: 0.0213 - val_loss: 0.0277 - 159ms/epoch - 32ms/step\n",
      "Epoch 344/900\n",
      "5/5 - 0s - loss: 0.0212 - val_loss: 0.0277 - 163ms/epoch - 33ms/step\n",
      "Epoch 345/900\n",
      "5/5 - 0s - loss: 0.0212 - val_loss: 0.0282 - 155ms/epoch - 31ms/step\n",
      "Epoch 346/900\n",
      "5/5 - 0s - loss: 0.0216 - val_loss: 0.0285 - 161ms/epoch - 32ms/step\n",
      "Epoch 347/900\n",
      "5/5 - 0s - loss: 0.0220 - val_loss: 0.0300 - 155ms/epoch - 31ms/step\n",
      "Epoch 348/900\n",
      "5/5 - 0s - loss: 0.0220 - val_loss: 0.0282 - 153ms/epoch - 31ms/step\n",
      "Epoch 349/900\n",
      "5/5 - 0s - loss: 0.0222 - val_loss: 0.0306 - 150ms/epoch - 30ms/step\n",
      "Epoch 350/900\n",
      "5/5 - 0s - loss: 0.0224 - val_loss: 0.0298 - 154ms/epoch - 31ms/step\n",
      "Epoch 351/900\n",
      "5/5 - 0s - loss: 0.0219 - val_loss: 0.0296 - 152ms/epoch - 30ms/step\n",
      "Epoch 352/900\n",
      "5/5 - 0s - loss: 0.0217 - val_loss: 0.0285 - 157ms/epoch - 31ms/step\n",
      "Epoch 353/900\n",
      "5/5 - 0s - loss: 0.0215 - val_loss: 0.0278 - 156ms/epoch - 31ms/step\n",
      "Epoch 354/900\n",
      "5/5 - 0s - loss: 0.0210 - val_loss: 0.0279 - 156ms/epoch - 31ms/step\n",
      "Epoch 355/900\n",
      "5/5 - 0s - loss: 0.0211 - val_loss: 0.0276 - 157ms/epoch - 31ms/step\n",
      "Epoch 356/900\n",
      "5/5 - 0s - loss: 0.0210 - val_loss: 0.0276 - 157ms/epoch - 31ms/step\n",
      "Epoch 357/900\n",
      "5/5 - 0s - loss: 0.0211 - val_loss: 0.0273 - 158ms/epoch - 32ms/step\n",
      "Epoch 358/900\n",
      "5/5 - 0s - loss: 0.0211 - val_loss: 0.0289 - 156ms/epoch - 31ms/step\n",
      "Epoch 359/900\n",
      "5/5 - 0s - loss: 0.0213 - val_loss: 0.0273 - 160ms/epoch - 32ms/step\n",
      "Epoch 360/900\n",
      "5/5 - 0s - loss: 0.0211 - val_loss: 0.0284 - 156ms/epoch - 31ms/step\n",
      "Epoch 361/900\n",
      "5/5 - 0s - loss: 0.0213 - val_loss: 0.0280 - 153ms/epoch - 31ms/step\n",
      "Epoch 362/900\n",
      "5/5 - 0s - loss: 0.0212 - val_loss: 0.0277 - 155ms/epoch - 31ms/step\n",
      "Epoch 363/900\n",
      "5/5 - 0s - loss: 0.0209 - val_loss: 0.0273 - 155ms/epoch - 31ms/step\n",
      "Epoch 364/900\n",
      "5/5 - 0s - loss: 0.0209 - val_loss: 0.0281 - 154ms/epoch - 31ms/step\n",
      "Epoch 365/900\n",
      "5/5 - 0s - loss: 0.0212 - val_loss: 0.0289 - 154ms/epoch - 31ms/step\n",
      "Epoch 366/900\n",
      "5/5 - 0s - loss: 0.0216 - val_loss: 0.0283 - 156ms/epoch - 31ms/step\n",
      "Epoch 367/900\n",
      "5/5 - 0s - loss: 0.0216 - val_loss: 0.0281 - 157ms/epoch - 31ms/step\n",
      "Epoch 368/900\n",
      "5/5 - 0s - loss: 0.0210 - val_loss: 0.0276 - 155ms/epoch - 31ms/step\n",
      "Epoch 369/900\n",
      "5/5 - 0s - loss: 0.0207 - val_loss: 0.0270 - 153ms/epoch - 31ms/step\n",
      "Epoch 370/900\n",
      "5/5 - 0s - loss: 0.0205 - val_loss: 0.0271 - 153ms/epoch - 31ms/step\n",
      "Epoch 371/900\n",
      "5/5 - 0s - loss: 0.0207 - val_loss: 0.0274 - 155ms/epoch - 31ms/step\n",
      "Epoch 372/900\n",
      "5/5 - 0s - loss: 0.0206 - val_loss: 0.0271 - 151ms/epoch - 30ms/step\n",
      "Epoch 373/900\n",
      "5/5 - 0s - loss: 0.0205 - val_loss: 0.0271 - 151ms/epoch - 30ms/step\n",
      "Epoch 374/900\n",
      "5/5 - 0s - loss: 0.0206 - val_loss: 0.0272 - 154ms/epoch - 31ms/step\n",
      "Epoch 375/900\n",
      "5/5 - 0s - loss: 0.0208 - val_loss: 0.0273 - 153ms/epoch - 31ms/step\n",
      "Epoch 376/900\n",
      "5/5 - 0s - loss: 0.0206 - val_loss: 0.0281 - 152ms/epoch - 30ms/step\n",
      "Epoch 377/900\n",
      "5/5 - 0s - loss: 0.0207 - val_loss: 0.0268 - 154ms/epoch - 31ms/step\n",
      "Epoch 378/900\n",
      "5/5 - 0s - loss: 0.0207 - val_loss: 0.0279 - 155ms/epoch - 31ms/step\n",
      "Epoch 379/900\n",
      "5/5 - 0s - loss: 0.0207 - val_loss: 0.0270 - 161ms/epoch - 32ms/step\n",
      "Epoch 380/900\n",
      "5/5 - 0s - loss: 0.0206 - val_loss: 0.0273 - 156ms/epoch - 31ms/step\n",
      "Epoch 381/900\n",
      "5/5 - 0s - loss: 0.0203 - val_loss: 0.0270 - 157ms/epoch - 31ms/step\n",
      "Epoch 382/900\n",
      "5/5 - 0s - loss: 0.0203 - val_loss: 0.0268 - 155ms/epoch - 31ms/step\n",
      "Epoch 383/900\n",
      "5/5 - 0s - loss: 0.0204 - val_loss: 0.0268 - 159ms/epoch - 32ms/step\n",
      "Epoch 384/900\n",
      "5/5 - 0s - loss: 0.0204 - val_loss: 0.0267 - 154ms/epoch - 31ms/step\n",
      "Epoch 385/900\n",
      "5/5 - 0s - loss: 0.0202 - val_loss: 0.0269 - 154ms/epoch - 31ms/step\n",
      "Epoch 386/900\n",
      "5/5 - 0s - loss: 0.0203 - val_loss: 0.0275 - 155ms/epoch - 31ms/step\n",
      "Epoch 387/900\n",
      "5/5 - 0s - loss: 0.0204 - val_loss: 0.0266 - 155ms/epoch - 31ms/step\n",
      "Epoch 388/900\n",
      "5/5 - 0s - loss: 0.0202 - val_loss: 0.0267 - 154ms/epoch - 31ms/step\n",
      "Epoch 389/900\n",
      "5/5 - 0s - loss: 0.0201 - val_loss: 0.0269 - 155ms/epoch - 31ms/step\n",
      "Epoch 390/900\n",
      "5/5 - 0s - loss: 0.0202 - val_loss: 0.0270 - 154ms/epoch - 31ms/step\n",
      "Epoch 391/900\n",
      "5/5 - 0s - loss: 0.0203 - val_loss: 0.0266 - 155ms/epoch - 31ms/step\n",
      "Epoch 392/900\n",
      "5/5 - 0s - loss: 0.0201 - val_loss: 0.0268 - 154ms/epoch - 31ms/step\n",
      "Epoch 393/900\n",
      "5/5 - 0s - loss: 0.0201 - val_loss: 0.0266 - 155ms/epoch - 31ms/step\n",
      "Epoch 394/900\n",
      "5/5 - 0s - loss: 0.0201 - val_loss: 0.0264 - 157ms/epoch - 31ms/step\n",
      "Epoch 395/900\n",
      "5/5 - 0s - loss: 0.0200 - val_loss: 0.0264 - 155ms/epoch - 31ms/step\n",
      "Epoch 396/900\n",
      "5/5 - 0s - loss: 0.0201 - val_loss: 0.0278 - 155ms/epoch - 31ms/step\n",
      "Epoch 397/900\n",
      "5/5 - 0s - loss: 0.0207 - val_loss: 0.0268 - 154ms/epoch - 31ms/step\n",
      "Epoch 398/900\n",
      "5/5 - 0s - loss: 0.0208 - val_loss: 0.0273 - 154ms/epoch - 31ms/step\n",
      "Epoch 399/900\n",
      "5/5 - 0s - loss: 0.0204 - val_loss: 0.0264 - 153ms/epoch - 31ms/step\n",
      "Epoch 400/900\n",
      "5/5 - 0s - loss: 0.0207 - val_loss: 0.0273 - 153ms/epoch - 31ms/step\n",
      "Epoch 401/900\n",
      "5/5 - 0s - loss: 0.0202 - val_loss: 0.0269 - 154ms/epoch - 31ms/step\n",
      "Epoch 402/900\n",
      "5/5 - 0s - loss: 0.0203 - val_loss: 0.0263 - 153ms/epoch - 31ms/step\n",
      "Epoch 403/900\n",
      "5/5 - 0s - loss: 0.0200 - val_loss: 0.0266 - 158ms/epoch - 32ms/step\n",
      "Epoch 404/900\n",
      "5/5 - 0s - loss: 0.0201 - val_loss: 0.0268 - 157ms/epoch - 31ms/step\n",
      "Epoch 405/900\n",
      "5/5 - 0s - loss: 0.0201 - val_loss: 0.0268 - 155ms/epoch - 31ms/step\n",
      "Epoch 406/900\n",
      "5/5 - 0s - loss: 0.0201 - val_loss: 0.0267 - 154ms/epoch - 31ms/step\n",
      "Epoch 407/900\n",
      "5/5 - 0s - loss: 0.0200 - val_loss: 0.0262 - 155ms/epoch - 31ms/step\n",
      "Epoch 408/900\n",
      "5/5 - 0s - loss: 0.0199 - val_loss: 0.0263 - 155ms/epoch - 31ms/step\n",
      "Epoch 409/900\n",
      "5/5 - 0s - loss: 0.0198 - val_loss: 0.0265 - 153ms/epoch - 31ms/step\n",
      "Epoch 410/900\n",
      "5/5 - 0s - loss: 0.0198 - val_loss: 0.0262 - 154ms/epoch - 31ms/step\n",
      "Epoch 411/900\n",
      "5/5 - 0s - loss: 0.0200 - val_loss: 0.0262 - 154ms/epoch - 31ms/step\n",
      "Epoch 412/900\n",
      "5/5 - 0s - loss: 0.0199 - val_loss: 0.0261 - 152ms/epoch - 30ms/step\n",
      "Epoch 413/900\n",
      "5/5 - 0s - loss: 0.0200 - val_loss: 0.0276 - 153ms/epoch - 31ms/step\n",
      "Epoch 414/900\n",
      "5/5 - 0s - loss: 0.0201 - val_loss: 0.0268 - 184ms/epoch - 37ms/step\n",
      "Epoch 415/900\n",
      "5/5 - 0s - loss: 0.0199 - val_loss: 0.0260 - 169ms/epoch - 34ms/step\n",
      "Epoch 416/900\n",
      "5/5 - 0s - loss: 0.0197 - val_loss: 0.0268 - 152ms/epoch - 30ms/step\n",
      "Epoch 417/900\n",
      "5/5 - 0s - loss: 0.0201 - val_loss: 0.0261 - 154ms/epoch - 31ms/step\n",
      "Epoch 418/900\n",
      "5/5 - 0s - loss: 0.0203 - val_loss: 0.0268 - 158ms/epoch - 32ms/step\n",
      "Epoch 419/900\n",
      "5/5 - 0s - loss: 0.0198 - val_loss: 0.0259 - 162ms/epoch - 32ms/step\n",
      "Epoch 420/900\n",
      "5/5 - 0s - loss: 0.0197 - val_loss: 0.0260 - 154ms/epoch - 31ms/step\n",
      "Epoch 421/900\n",
      "5/5 - 0s - loss: 0.0197 - val_loss: 0.0262 - 153ms/epoch - 31ms/step\n",
      "Epoch 422/900\n",
      "5/5 - 0s - loss: 0.0197 - val_loss: 0.0260 - 152ms/epoch - 30ms/step\n",
      "Epoch 423/900\n",
      "5/5 - 0s - loss: 0.0196 - val_loss: 0.0259 - 154ms/epoch - 31ms/step\n",
      "Epoch 424/900\n",
      "5/5 - 0s - loss: 0.0196 - val_loss: 0.0266 - 150ms/epoch - 30ms/step\n",
      "Epoch 425/900\n",
      "5/5 - 0s - loss: 0.0199 - val_loss: 0.0260 - 152ms/epoch - 30ms/step\n",
      "Epoch 426/900\n",
      "5/5 - 0s - loss: 0.0197 - val_loss: 0.0263 - 152ms/epoch - 30ms/step\n",
      "Epoch 427/900\n",
      "5/5 - 0s - loss: 0.0197 - val_loss: 0.0264 - 151ms/epoch - 30ms/step\n",
      "Epoch 428/900\n",
      "5/5 - 0s - loss: 0.0196 - val_loss: 0.0259 - 153ms/epoch - 31ms/step\n",
      "Epoch 429/900\n",
      "5/5 - 0s - loss: 0.0195 - val_loss: 0.0259 - 157ms/epoch - 31ms/step\n",
      "Epoch 430/900\n",
      "5/5 - 0s - loss: 0.0195 - val_loss: 0.0259 - 156ms/epoch - 31ms/step\n",
      "Epoch 431/900\n",
      "5/5 - 0s - loss: 0.0195 - val_loss: 0.0258 - 160ms/epoch - 32ms/step\n",
      "Epoch 432/900\n",
      "5/5 - 0s - loss: 0.0197 - val_loss: 0.0268 - 154ms/epoch - 31ms/step\n",
      "Epoch 433/900\n",
      "5/5 - 0s - loss: 0.0197 - val_loss: 0.0261 - 156ms/epoch - 31ms/step\n",
      "Epoch 434/900\n",
      "5/5 - 0s - loss: 0.0200 - val_loss: 0.0261 - 163ms/epoch - 33ms/step\n",
      "Epoch 435/900\n",
      "5/5 - 0s - loss: 0.0200 - val_loss: 0.0282 - 162ms/epoch - 32ms/step\n",
      "Epoch 436/900\n",
      "5/5 - 0s - loss: 0.0206 - val_loss: 0.0273 - 156ms/epoch - 31ms/step\n",
      "Epoch 437/900\n",
      "5/5 - 0s - loss: 0.0200 - val_loss: 0.0260 - 155ms/epoch - 31ms/step\n",
      "Epoch 438/900\n",
      "5/5 - 0s - loss: 0.0198 - val_loss: 0.0270 - 155ms/epoch - 31ms/step\n",
      "Epoch 439/900\n",
      "5/5 - 0s - loss: 0.0199 - val_loss: 0.0257 - 162ms/epoch - 32ms/step\n",
      "Epoch 440/900\n",
      "5/5 - 0s - loss: 0.0196 - val_loss: 0.0270 - 154ms/epoch - 31ms/step\n",
      "Epoch 441/900\n",
      "5/5 - 0s - loss: 0.0197 - val_loss: 0.0259 - 153ms/epoch - 31ms/step\n",
      "Epoch 442/900\n",
      "5/5 - 0s - loss: 0.0194 - val_loss: 0.0258 - 156ms/epoch - 31ms/step\n",
      "Epoch 443/900\n",
      "5/5 - 0s - loss: 0.0193 - val_loss: 0.0257 - 156ms/epoch - 31ms/step\n",
      "Epoch 444/900\n",
      "5/5 - 0s - loss: 0.0195 - val_loss: 0.0257 - 153ms/epoch - 31ms/step\n",
      "Epoch 445/900\n",
      "5/5 - 0s - loss: 0.0194 - val_loss: 0.0258 - 154ms/epoch - 31ms/step\n",
      "Epoch 446/900\n",
      "5/5 - 0s - loss: 0.0194 - val_loss: 0.0261 - 156ms/epoch - 31ms/step\n",
      "Epoch 447/900\n",
      "5/5 - 0s - loss: 0.0195 - val_loss: 0.0257 - 155ms/epoch - 31ms/step\n",
      "Epoch 448/900\n",
      "5/5 - 0s - loss: 0.0195 - val_loss: 0.0265 - 155ms/epoch - 31ms/step\n",
      "Epoch 449/900\n",
      "5/5 - 0s - loss: 0.0193 - val_loss: 0.0261 - 154ms/epoch - 31ms/step\n",
      "Epoch 450/900\n",
      "5/5 - 0s - loss: 0.0194 - val_loss: 0.0256 - 156ms/epoch - 31ms/step\n",
      "Epoch 451/900\n",
      "5/5 - 0s - loss: 0.0194 - val_loss: 0.0257 - 155ms/epoch - 31ms/step\n",
      "Epoch 452/900\n",
      "5/5 - 0s - loss: 0.0192 - val_loss: 0.0255 - 155ms/epoch - 31ms/step\n",
      "Epoch 453/900\n",
      "5/5 - 0s - loss: 0.0192 - val_loss: 0.0263 - 155ms/epoch - 31ms/step\n",
      "Epoch 454/900\n",
      "5/5 - 0s - loss: 0.0195 - val_loss: 0.0258 - 155ms/epoch - 31ms/step\n",
      "Epoch 455/900\n",
      "5/5 - 0s - loss: 0.0193 - val_loss: 0.0255 - 157ms/epoch - 31ms/step\n",
      "Epoch 456/900\n",
      "5/5 - 0s - loss: 0.0193 - val_loss: 0.0263 - 157ms/epoch - 31ms/step\n",
      "Epoch 457/900\n",
      "5/5 - 0s - loss: 0.0194 - val_loss: 0.0255 - 155ms/epoch - 31ms/step\n",
      "Epoch 458/900\n",
      "5/5 - 0s - loss: 0.0193 - val_loss: 0.0254 - 159ms/epoch - 32ms/step\n",
      "Epoch 459/900\n",
      "5/5 - 0s - loss: 0.0191 - val_loss: 0.0255 - 155ms/epoch - 31ms/step\n",
      "Epoch 460/900\n",
      "5/5 - 0s - loss: 0.0195 - val_loss: 0.0255 - 156ms/epoch - 31ms/step\n",
      "Epoch 461/900\n",
      "5/5 - 0s - loss: 0.0194 - val_loss: 0.0257 - 157ms/epoch - 31ms/step\n",
      "Epoch 462/900\n",
      "5/5 - 0s - loss: 0.0193 - val_loss: 0.0258 - 173ms/epoch - 35ms/step\n",
      "Epoch 463/900\n",
      "5/5 - 0s - loss: 0.0194 - val_loss: 0.0258 - 159ms/epoch - 32ms/step\n",
      "Epoch 464/900\n",
      "5/5 - 0s - loss: 0.0195 - val_loss: 0.0258 - 166ms/epoch - 33ms/step\n",
      "Epoch 465/900\n",
      "5/5 - 0s - loss: 0.0193 - val_loss: 0.0255 - 166ms/epoch - 33ms/step\n",
      "Epoch 466/900\n",
      "5/5 - 0s - loss: 0.0192 - val_loss: 0.0256 - 171ms/epoch - 34ms/step\n",
      "Epoch 467/900\n",
      "5/5 - 0s - loss: 0.0192 - val_loss: 0.0253 - 163ms/epoch - 33ms/step\n",
      "Epoch 468/900\n",
      "5/5 - 0s - loss: 0.0192 - val_loss: 0.0263 - 170ms/epoch - 34ms/step\n",
      "Epoch 469/900\n",
      "5/5 - 0s - loss: 0.0193 - val_loss: 0.0253 - 179ms/epoch - 36ms/step\n",
      "Epoch 470/900\n",
      "5/5 - 0s - loss: 0.0193 - val_loss: 0.0265 - 176ms/epoch - 35ms/step\n",
      "Epoch 471/900\n",
      "5/5 - 0s - loss: 0.0198 - val_loss: 0.0255 - 164ms/epoch - 33ms/step\n",
      "Epoch 472/900\n",
      "5/5 - 0s - loss: 0.0194 - val_loss: 0.0269 - 154ms/epoch - 31ms/step\n",
      "Epoch 473/900\n",
      "5/5 - 0s - loss: 0.0194 - val_loss: 0.0254 - 156ms/epoch - 31ms/step\n",
      "Epoch 474/900\n",
      "5/5 - 0s - loss: 0.0194 - val_loss: 0.0255 - 163ms/epoch - 33ms/step\n",
      "Epoch 475/900\n",
      "5/5 - 0s - loss: 0.0190 - val_loss: 0.0256 - 164ms/epoch - 33ms/step\n",
      "Epoch 476/900\n",
      "5/5 - 0s - loss: 0.0191 - val_loss: 0.0254 - 166ms/epoch - 33ms/step\n",
      "Epoch 477/900\n",
      "5/5 - 0s - loss: 0.0190 - val_loss: 0.0253 - 165ms/epoch - 33ms/step\n",
      "Epoch 478/900\n",
      "5/5 - 0s - loss: 0.0190 - val_loss: 0.0256 - 169ms/epoch - 34ms/step\n",
      "Epoch 479/900\n",
      "5/5 - 0s - loss: 0.0193 - val_loss: 0.0267 - 174ms/epoch - 35ms/step\n",
      "Epoch 480/900\n",
      "5/5 - 0s - loss: 0.0193 - val_loss: 0.0253 - 170ms/epoch - 34ms/step\n",
      "Epoch 481/900\n",
      "5/5 - 0s - loss: 0.0189 - val_loss: 0.0254 - 188ms/epoch - 38ms/step\n",
      "Epoch 482/900\n",
      "5/5 - 0s - loss: 0.0190 - val_loss: 0.0252 - 213ms/epoch - 43ms/step\n",
      "Epoch 483/900\n",
      "5/5 - 0s - loss: 0.0190 - val_loss: 0.0252 - 182ms/epoch - 36ms/step\n",
      "Epoch 484/900\n",
      "5/5 - 0s - loss: 0.0189 - val_loss: 0.0256 - 184ms/epoch - 37ms/step\n",
      "Epoch 485/900\n",
      "5/5 - 0s - loss: 0.0191 - val_loss: 0.0259 - 172ms/epoch - 34ms/step\n",
      "Epoch 486/900\n",
      "5/5 - 0s - loss: 0.0192 - val_loss: 0.0254 - 160ms/epoch - 32ms/step\n",
      "Epoch 487/900\n",
      "5/5 - 0s - loss: 0.0195 - val_loss: 0.0275 - 160ms/epoch - 32ms/step\n",
      "Epoch 488/900\n",
      "5/5 - 0s - loss: 0.0199 - val_loss: 0.0253 - 164ms/epoch - 33ms/step\n",
      "Epoch 489/900\n",
      "5/5 - 0s - loss: 0.0192 - val_loss: 0.0271 - 174ms/epoch - 35ms/step\n",
      "Epoch 490/900\n",
      "5/5 - 0s - loss: 0.0196 - val_loss: 0.0252 - 168ms/epoch - 34ms/step\n",
      "Epoch 491/900\n",
      "5/5 - 0s - loss: 0.0197 - val_loss: 0.0301 - 163ms/epoch - 33ms/step\n",
      "Epoch 492/900\n",
      "5/5 - 0s - loss: 0.0207 - val_loss: 0.0261 - 165ms/epoch - 33ms/step\n",
      "Epoch 493/900\n",
      "5/5 - 0s - loss: 0.0200 - val_loss: 0.0271 - 162ms/epoch - 32ms/step\n",
      "Epoch 494/900\n",
      "5/5 - 0s - loss: 0.0198 - val_loss: 0.0253 - 162ms/epoch - 32ms/step\n",
      "Epoch 495/900\n",
      "5/5 - 0s - loss: 0.0190 - val_loss: 0.0254 - 163ms/epoch - 33ms/step\n",
      "Epoch 496/900\n",
      "5/5 - 0s - loss: 0.0188 - val_loss: 0.0256 - 163ms/epoch - 33ms/step\n",
      "Epoch 497/900\n",
      "5/5 - 0s - loss: 0.0190 - val_loss: 0.0256 - 159ms/epoch - 32ms/step\n",
      "Epoch 498/900\n",
      "5/5 - 0s - loss: 0.0192 - val_loss: 0.0265 - 161ms/epoch - 32ms/step\n",
      "Epoch 499/900\n",
      "5/5 - 0s - loss: 0.0194 - val_loss: 0.0251 - 165ms/epoch - 33ms/step\n",
      "Epoch 500/900\n",
      "5/5 - 0s - loss: 0.0192 - val_loss: 0.0280 - 162ms/epoch - 32ms/step\n",
      "Epoch 501/900\n",
      "5/5 - 0s - loss: 0.0198 - val_loss: 0.0257 - 157ms/epoch - 31ms/step\n",
      "Epoch 502/900\n",
      "5/5 - 0s - loss: 0.0196 - val_loss: 0.0268 - 166ms/epoch - 33ms/step\n",
      "Epoch 503/900\n",
      "5/5 - 0s - loss: 0.0198 - val_loss: 0.0271 - 168ms/epoch - 34ms/step\n",
      "Epoch 504/900\n",
      "5/5 - 0s - loss: 0.0192 - val_loss: 0.0250 - 173ms/epoch - 35ms/step\n",
      "Epoch 505/900\n",
      "5/5 - 0s - loss: 0.0193 - val_loss: 0.0272 - 170ms/epoch - 34ms/step\n",
      "Epoch 506/900\n",
      "5/5 - 0s - loss: 0.0196 - val_loss: 0.0251 - 182ms/epoch - 36ms/step\n",
      "Epoch 507/900\n",
      "5/5 - 0s - loss: 0.0191 - val_loss: 0.0262 - 168ms/epoch - 34ms/step\n",
      "Epoch 508/900\n",
      "5/5 - 0s - loss: 0.0194 - val_loss: 0.0250 - 163ms/epoch - 33ms/step\n",
      "Epoch 509/900\n",
      "5/5 - 0s - loss: 0.0189 - val_loss: 0.0250 - 162ms/epoch - 32ms/step\n",
      "Epoch 510/900\n",
      "5/5 - 0s - loss: 0.0186 - val_loss: 0.0252 - 166ms/epoch - 33ms/step\n",
      "Epoch 511/900\n",
      "5/5 - 0s - loss: 0.0186 - val_loss: 0.0251 - 165ms/epoch - 33ms/step\n",
      "Epoch 512/900\n",
      "5/5 - 0s - loss: 0.0187 - val_loss: 0.0252 - 166ms/epoch - 33ms/step\n",
      "Epoch 513/900\n",
      "5/5 - 0s - loss: 0.0187 - val_loss: 0.0250 - 161ms/epoch - 32ms/step\n",
      "Epoch 514/900\n",
      "5/5 - 0s - loss: 0.0186 - val_loss: 0.0249 - 164ms/epoch - 33ms/step\n",
      "Epoch 515/900\n",
      "5/5 - 0s - loss: 0.0186 - val_loss: 0.0252 - 163ms/epoch - 33ms/step\n",
      "Epoch 516/900\n",
      "5/5 - 0s - loss: 0.0188 - val_loss: 0.0254 - 170ms/epoch - 34ms/step\n",
      "Epoch 517/900\n",
      "5/5 - 0s - loss: 0.0188 - val_loss: 0.0262 - 163ms/epoch - 33ms/step\n",
      "Epoch 518/900\n",
      "5/5 - 0s - loss: 0.0190 - val_loss: 0.0252 - 163ms/epoch - 33ms/step\n",
      "Epoch 519/900\n",
      "5/5 - 0s - loss: 0.0189 - val_loss: 0.0251 - 151ms/epoch - 30ms/step\n",
      "Epoch 520/900\n",
      "5/5 - 0s - loss: 0.0189 - val_loss: 0.0265 - 173ms/epoch - 35ms/step\n",
      "Epoch 521/900\n",
      "5/5 - 0s - loss: 0.0195 - val_loss: 0.0272 - 154ms/epoch - 31ms/step\n",
      "Epoch 522/900\n",
      "5/5 - 0s - loss: 0.0197 - val_loss: 0.0251 - 143ms/epoch - 29ms/step\n",
      "Epoch 523/900\n",
      "5/5 - 0s - loss: 0.0188 - val_loss: 0.0253 - 145ms/epoch - 29ms/step\n",
      "Epoch 524/900\n",
      "5/5 - 0s - loss: 0.0189 - val_loss: 0.0254 - 144ms/epoch - 29ms/step\n",
      "Epoch 525/900\n",
      "5/5 - 0s - loss: 0.0188 - val_loss: 0.0252 - 179ms/epoch - 36ms/step\n",
      "Epoch 526/900\n",
      "5/5 - 0s - loss: 0.0187 - val_loss: 0.0251 - 146ms/epoch - 29ms/step\n",
      "Epoch 527/900\n",
      "5/5 - 0s - loss: 0.0187 - val_loss: 0.0255 - 180ms/epoch - 36ms/step\n",
      "Epoch 528/900\n",
      "5/5 - 0s - loss: 0.0187 - val_loss: 0.0248 - 157ms/epoch - 31ms/step\n",
      "Epoch 529/900\n",
      "5/5 - 0s - loss: 0.0186 - val_loss: 0.0275 - 151ms/epoch - 30ms/step\n",
      "Epoch 530/900\n",
      "5/5 - 0s - loss: 0.0193 - val_loss: 0.0248 - 146ms/epoch - 29ms/step\n",
      "Epoch 531/900\n",
      "5/5 - 0s - loss: 0.0188 - val_loss: 0.0255 - 148ms/epoch - 30ms/step\n",
      "Epoch 532/900\n",
      "5/5 - 0s - loss: 0.0188 - val_loss: 0.0250 - 149ms/epoch - 30ms/step\n",
      "Epoch 533/900\n",
      "5/5 - 0s - loss: 0.0186 - val_loss: 0.0257 - 145ms/epoch - 29ms/step\n",
      "Epoch 534/900\n",
      "5/5 - 0s - loss: 0.0187 - val_loss: 0.0259 - 146ms/epoch - 29ms/step\n",
      "Epoch 535/900\n",
      "5/5 - 0s - loss: 0.0189 - val_loss: 0.0251 - 154ms/epoch - 31ms/step\n",
      "Epoch 536/900\n",
      "5/5 - 0s - loss: 0.0191 - val_loss: 0.0258 - 147ms/epoch - 29ms/step\n",
      "Epoch 537/900\n",
      "5/5 - 0s - loss: 0.0189 - val_loss: 0.0250 - 153ms/epoch - 31ms/step\n",
      "Epoch 538/900\n",
      "5/5 - 0s - loss: 0.0186 - val_loss: 0.0248 - 143ms/epoch - 29ms/step\n",
      "Epoch 539/900\n",
      "5/5 - 0s - loss: 0.0185 - val_loss: 0.0252 - 143ms/epoch - 29ms/step\n",
      "Epoch 540/900\n",
      "5/5 - 0s - loss: 0.0185 - val_loss: 0.0250 - 155ms/epoch - 31ms/step\n",
      "Epoch 541/900\n",
      "5/5 - 0s - loss: 0.0186 - val_loss: 0.0256 - 152ms/epoch - 30ms/step\n",
      "Epoch 542/900\n",
      "5/5 - 0s - loss: 0.0186 - val_loss: 0.0248 - 156ms/epoch - 31ms/step\n",
      "Epoch 543/900\n",
      "5/5 - 0s - loss: 0.0186 - val_loss: 0.0251 - 150ms/epoch - 30ms/step\n",
      "Epoch 544/900\n",
      "5/5 - 0s - loss: 0.0185 - val_loss: 0.0250 - 150ms/epoch - 30ms/step\n",
      "Epoch 545/900\n",
      "5/5 - 0s - loss: 0.0185 - val_loss: 0.0248 - 151ms/epoch - 30ms/step\n",
      "Epoch 546/900\n",
      "5/5 - 0s - loss: 0.0184 - val_loss: 0.0266 - 157ms/epoch - 31ms/step\n",
      "Epoch 547/900\n",
      "5/5 - 0s - loss: 0.0192 - val_loss: 0.0255 - 152ms/epoch - 30ms/step\n",
      "Epoch 548/900\n",
      "5/5 - 0s - loss: 0.0194 - val_loss: 0.0247 - 148ms/epoch - 30ms/step\n",
      "Epoch 549/900\n",
      "5/5 - 0s - loss: 0.0189 - val_loss: 0.0264 - 158ms/epoch - 32ms/step\n",
      "Epoch 550/900\n",
      "5/5 - 0s - loss: 0.0191 - val_loss: 0.0247 - 158ms/epoch - 32ms/step\n",
      "Epoch 551/900\n",
      "5/5 - 0s - loss: 0.0195 - val_loss: 0.0275 - 143ms/epoch - 29ms/step\n",
      "Epoch 552/900\n",
      "5/5 - 0s - loss: 0.0199 - val_loss: 0.0285 - 153ms/epoch - 31ms/step\n",
      "Epoch 553/900\n",
      "5/5 - 0s - loss: 0.0200 - val_loss: 0.0246 - 142ms/epoch - 28ms/step\n",
      "Epoch 554/900\n",
      "5/5 - 0s - loss: 0.0185 - val_loss: 0.0253 - 150ms/epoch - 30ms/step\n",
      "Epoch 555/900\n",
      "5/5 - 0s - loss: 0.0184 - val_loss: 0.0246 - 144ms/epoch - 29ms/step\n",
      "Epoch 556/900\n",
      "5/5 - 0s - loss: 0.0183 - val_loss: 0.0249 - 146ms/epoch - 29ms/step\n",
      "Epoch 557/900\n",
      "5/5 - 0s - loss: 0.0185 - val_loss: 0.0256 - 149ms/epoch - 30ms/step\n",
      "Epoch 558/900\n",
      "5/5 - 0s - loss: 0.0186 - val_loss: 0.0245 - 146ms/epoch - 29ms/step\n",
      "Epoch 559/900\n",
      "5/5 - 0s - loss: 0.0185 - val_loss: 0.0250 - 144ms/epoch - 29ms/step\n",
      "Epoch 560/900\n",
      "5/5 - 0s - loss: 0.0186 - val_loss: 0.0246 - 145ms/epoch - 29ms/step\n",
      "Epoch 561/900\n",
      "5/5 - 0s - loss: 0.0184 - val_loss: 0.0262 - 145ms/epoch - 29ms/step\n",
      "Epoch 562/900\n",
      "5/5 - 0s - loss: 0.0186 - val_loss: 0.0248 - 143ms/epoch - 29ms/step\n",
      "Epoch 563/900\n",
      "5/5 - 0s - loss: 0.0184 - val_loss: 0.0252 - 165ms/epoch - 33ms/step\n",
      "Epoch 564/900\n",
      "5/5 - 0s - loss: 0.0187 - val_loss: 0.0247 - 161ms/epoch - 32ms/step\n",
      "Epoch 565/900\n",
      "5/5 - 0s - loss: 0.0185 - val_loss: 0.0262 - 151ms/epoch - 30ms/step\n",
      "Epoch 566/900\n",
      "5/5 - 0s - loss: 0.0191 - val_loss: 0.0255 - 149ms/epoch - 30ms/step\n",
      "Epoch 567/900\n",
      "5/5 - 0s - loss: 0.0189 - val_loss: 0.0272 - 144ms/epoch - 29ms/step\n",
      "Epoch 568/900\n",
      "5/5 - 0s - loss: 0.0192 - val_loss: 0.0257 - 151ms/epoch - 30ms/step\n",
      "Epoch 569/900\n",
      "5/5 - 0s - loss: 0.0192 - val_loss: 0.0255 - 152ms/epoch - 30ms/step\n",
      "Epoch 570/900\n",
      "5/5 - 0s - loss: 0.0194 - val_loss: 0.0247 - 163ms/epoch - 33ms/step\n",
      "Epoch 571/900\n",
      "5/5 - 0s - loss: 0.0193 - val_loss: 0.0256 - 145ms/epoch - 29ms/step\n",
      "Epoch 572/900\n",
      "5/5 - 0s - loss: 0.0191 - val_loss: 0.0275 - 154ms/epoch - 31ms/step\n",
      "Epoch 573/900\n",
      "5/5 - 0s - loss: 0.0192 - val_loss: 0.0247 - 199ms/epoch - 40ms/step\n",
      "Epoch 574/900\n",
      "5/5 - 0s - loss: 0.0188 - val_loss: 0.0256 - 183ms/epoch - 37ms/step\n",
      "Epoch 575/900\n",
      "5/5 - 0s - loss: 0.0191 - val_loss: 0.0264 - 144ms/epoch - 29ms/step\n",
      "Epoch 576/900\n",
      "5/5 - 0s - loss: 0.0187 - val_loss: 0.0248 - 149ms/epoch - 30ms/step\n",
      "Epoch 577/900\n",
      "5/5 - 0s - loss: 0.0190 - val_loss: 0.0245 - 148ms/epoch - 30ms/step\n",
      "Epoch 578/900\n",
      "5/5 - 0s - loss: 0.0186 - val_loss: 0.0248 - 156ms/epoch - 31ms/step\n",
      "Epoch 579/900\n",
      "5/5 - 0s - loss: 0.0183 - val_loss: 0.0256 - 157ms/epoch - 31ms/step\n",
      "Epoch 580/900\n",
      "5/5 - 0s - loss: 0.0185 - val_loss: 0.0245 - 156ms/epoch - 31ms/step\n",
      "Epoch 581/900\n",
      "5/5 - 0s - loss: 0.0185 - val_loss: 0.0251 - 157ms/epoch - 31ms/step\n",
      "Epoch 582/900\n",
      "5/5 - 0s - loss: 0.0184 - val_loss: 0.0256 - 149ms/epoch - 30ms/step\n",
      "Epoch 583/900\n",
      "5/5 - 0s - loss: 0.0186 - val_loss: 0.0253 - 153ms/epoch - 31ms/step\n",
      "Epoch 584/900\n",
      "5/5 - 0s - loss: 0.0186 - val_loss: 0.0251 - 143ms/epoch - 29ms/step\n",
      "Epoch 585/900\n",
      "5/5 - 0s - loss: 0.0185 - val_loss: 0.0254 - 138ms/epoch - 28ms/step\n",
      "Epoch 586/900\n",
      "5/5 - 0s - loss: 0.0187 - val_loss: 0.0246 - 142ms/epoch - 28ms/step\n",
      "Epoch 587/900\n",
      "5/5 - 0s - loss: 0.0182 - val_loss: 0.0252 - 141ms/epoch - 28ms/step\n",
      "Epoch 588/900\n",
      "5/5 - 0s - loss: 0.0182 - val_loss: 0.0246 - 142ms/epoch - 28ms/step\n",
      "Epoch 589/900\n",
      "5/5 - 0s - loss: 0.0182 - val_loss: 0.0245 - 152ms/epoch - 30ms/step\n",
      "Epoch 590/900\n",
      "5/5 - 0s - loss: 0.0182 - val_loss: 0.0244 - 148ms/epoch - 30ms/step\n",
      "Epoch 591/900\n",
      "5/5 - 0s - loss: 0.0182 - val_loss: 0.0244 - 141ms/epoch - 28ms/step\n",
      "Epoch 592/900\n",
      "5/5 - 0s - loss: 0.0181 - val_loss: 0.0253 - 142ms/epoch - 28ms/step\n",
      "Epoch 593/900\n",
      "5/5 - 0s - loss: 0.0183 - val_loss: 0.0244 - 172ms/epoch - 34ms/step\n",
      "Epoch 594/900\n",
      "5/5 - 0s - loss: 0.0182 - val_loss: 0.0244 - 209ms/epoch - 42ms/step\n",
      "Epoch 595/900\n",
      "5/5 - 0s - loss: 0.0182 - val_loss: 0.0244 - 164ms/epoch - 33ms/step\n",
      "Epoch 596/900\n",
      "5/5 - 0s - loss: 0.0182 - val_loss: 0.0246 - 181ms/epoch - 36ms/step\n",
      "Epoch 597/900\n",
      "5/5 - 0s - loss: 0.0181 - val_loss: 0.0248 - 182ms/epoch - 36ms/step\n",
      "Epoch 598/900\n",
      "5/5 - 0s - loss: 0.0182 - val_loss: 0.0250 - 160ms/epoch - 32ms/step\n",
      "Epoch 599/900\n",
      "5/5 - 0s - loss: 0.0182 - val_loss: 0.0246 - 159ms/epoch - 32ms/step\n",
      "Epoch 600/900\n",
      "5/5 - 0s - loss: 0.0182 - val_loss: 0.0245 - 181ms/epoch - 36ms/step\n",
      "Epoch 601/900\n",
      "5/5 - 0s - loss: 0.0181 - val_loss: 0.0244 - 178ms/epoch - 36ms/step\n",
      "Epoch 602/900\n",
      "5/5 - 0s - loss: 0.0183 - val_loss: 0.0248 - 162ms/epoch - 32ms/step\n",
      "Epoch 603/900\n",
      "5/5 - 0s - loss: 0.0182 - val_loss: 0.0243 - 161ms/epoch - 32ms/step\n",
      "Epoch 604/900\n",
      "5/5 - 0s - loss: 0.0181 - val_loss: 0.0245 - 155ms/epoch - 31ms/step\n",
      "Epoch 605/900\n",
      "5/5 - 0s - loss: 0.0181 - val_loss: 0.0248 - 160ms/epoch - 32ms/step\n",
      "Epoch 606/900\n",
      "5/5 - 0s - loss: 0.0184 - val_loss: 0.0248 - 158ms/epoch - 32ms/step\n",
      "Epoch 607/900\n",
      "5/5 - 0s - loss: 0.0181 - val_loss: 0.0244 - 155ms/epoch - 31ms/step\n",
      "Epoch 608/900\n",
      "5/5 - 0s - loss: 0.0183 - val_loss: 0.0251 - 159ms/epoch - 32ms/step\n",
      "Epoch 609/900\n",
      "5/5 - 0s - loss: 0.0183 - val_loss: 0.0244 - 149ms/epoch - 30ms/step\n",
      "Epoch 610/900\n",
      "5/5 - 0s - loss: 0.0181 - val_loss: 0.0243 - 156ms/epoch - 31ms/step\n",
      "Epoch 611/900\n",
      "5/5 - 0s - loss: 0.0185 - val_loss: 0.0251 - 152ms/epoch - 30ms/step\n",
      "Epoch 612/900\n",
      "5/5 - 0s - loss: 0.0183 - val_loss: 0.0246 - 152ms/epoch - 30ms/step\n",
      "Epoch 613/900\n",
      "5/5 - 0s - loss: 0.0182 - val_loss: 0.0248 - 150ms/epoch - 30ms/step\n",
      "Epoch 614/900\n",
      "5/5 - 0s - loss: 0.0181 - val_loss: 0.0243 - 149ms/epoch - 30ms/step\n",
      "Epoch 615/900\n",
      "5/5 - 0s - loss: 0.0180 - val_loss: 0.0243 - 155ms/epoch - 31ms/step\n",
      "Epoch 616/900\n",
      "5/5 - 0s - loss: 0.0180 - val_loss: 0.0243 - 154ms/epoch - 31ms/step\n",
      "Epoch 617/900\n",
      "5/5 - 0s - loss: 0.0181 - val_loss: 0.0243 - 150ms/epoch - 30ms/step\n",
      "Epoch 618/900\n",
      "5/5 - 0s - loss: 0.0180 - val_loss: 0.0243 - 155ms/epoch - 31ms/step\n",
      "Epoch 619/900\n",
      "5/5 - 0s - loss: 0.0181 - val_loss: 0.0242 - 157ms/epoch - 31ms/step\n",
      "Epoch 620/900\n",
      "5/5 - 0s - loss: 0.0181 - val_loss: 0.0245 - 149ms/epoch - 30ms/step\n",
      "Epoch 621/900\n",
      "5/5 - 0s - loss: 0.0181 - val_loss: 0.0244 - 149ms/epoch - 30ms/step\n",
      "Epoch 622/900\n",
      "5/5 - 0s - loss: 0.0181 - val_loss: 0.0243 - 149ms/epoch - 30ms/step\n",
      "Epoch 623/900\n",
      "5/5 - 0s - loss: 0.0181 - val_loss: 0.0248 - 146ms/epoch - 29ms/step\n",
      "Epoch 624/900\n",
      "5/5 - 0s - loss: 0.0182 - val_loss: 0.0244 - 148ms/epoch - 30ms/step\n",
      "Epoch 625/900\n",
      "5/5 - 0s - loss: 0.0182 - val_loss: 0.0246 - 149ms/epoch - 30ms/step\n",
      "Epoch 626/900\n",
      "5/5 - 0s - loss: 0.0181 - val_loss: 0.0243 - 147ms/epoch - 29ms/step\n",
      "Epoch 627/900\n",
      "5/5 - 0s - loss: 0.0181 - val_loss: 0.0253 - 148ms/epoch - 30ms/step\n",
      "Epoch 628/900\n",
      "5/5 - 0s - loss: 0.0184 - val_loss: 0.0245 - 148ms/epoch - 30ms/step\n",
      "Epoch 629/900\n",
      "5/5 - 0s - loss: 0.0181 - val_loss: 0.0243 - 148ms/epoch - 30ms/step\n",
      "Epoch 630/900\n",
      "5/5 - 0s - loss: 0.0180 - val_loss: 0.0242 - 150ms/epoch - 30ms/step\n",
      "Epoch 631/900\n",
      "5/5 - 0s - loss: 0.0180 - val_loss: 0.0242 - 153ms/epoch - 31ms/step\n",
      "Epoch 632/900\n",
      "5/5 - 0s - loss: 0.0180 - val_loss: 0.0242 - 150ms/epoch - 30ms/step\n",
      "Epoch 633/900\n",
      "5/5 - 0s - loss: 0.0180 - val_loss: 0.0254 - 151ms/epoch - 30ms/step\n",
      "Epoch 634/900\n",
      "5/5 - 0s - loss: 0.0184 - val_loss: 0.0243 - 151ms/epoch - 30ms/step\n",
      "Epoch 635/900\n",
      "5/5 - 0s - loss: 0.0181 - val_loss: 0.0242 - 154ms/epoch - 31ms/step\n",
      "Epoch 636/900\n",
      "5/5 - 0s - loss: 0.0179 - val_loss: 0.0243 - 151ms/epoch - 30ms/step\n",
      "Epoch 637/900\n",
      "5/5 - 0s - loss: 0.0179 - val_loss: 0.0248 - 151ms/epoch - 30ms/step\n",
      "Epoch 638/900\n",
      "5/5 - 0s - loss: 0.0180 - val_loss: 0.0242 - 150ms/epoch - 30ms/step\n",
      "Epoch 639/900\n",
      "5/5 - 0s - loss: 0.0179 - val_loss: 0.0250 - 157ms/epoch - 31ms/step\n",
      "Epoch 640/900\n",
      "5/5 - 0s - loss: 0.0180 - val_loss: 0.0259 - 152ms/epoch - 30ms/step\n",
      "Epoch 641/900\n",
      "5/5 - 0s - loss: 0.0184 - val_loss: 0.0242 - 150ms/epoch - 30ms/step\n",
      "Epoch 642/900\n",
      "5/5 - 0s - loss: 0.0183 - val_loss: 0.0245 - 149ms/epoch - 30ms/step\n",
      "Epoch 643/900\n",
      "5/5 - 0s - loss: 0.0185 - val_loss: 0.0261 - 157ms/epoch - 31ms/step\n",
      "Epoch 644/900\n",
      "5/5 - 0s - loss: 0.0181 - val_loss: 0.0241 - 148ms/epoch - 30ms/step\n",
      "Epoch 645/900\n",
      "5/5 - 0s - loss: 0.0180 - val_loss: 0.0244 - 148ms/epoch - 30ms/step\n",
      "Epoch 646/900\n",
      "5/5 - 0s - loss: 0.0180 - val_loss: 0.0244 - 150ms/epoch - 30ms/step\n",
      "Epoch 647/900\n",
      "5/5 - 0s - loss: 0.0179 - val_loss: 0.0241 - 153ms/epoch - 31ms/step\n",
      "Epoch 648/900\n",
      "5/5 - 0s - loss: 0.0179 - val_loss: 0.0253 - 147ms/epoch - 29ms/step\n",
      "Epoch 649/900\n",
      "5/5 - 0s - loss: 0.0185 - val_loss: 0.0246 - 144ms/epoch - 29ms/step\n",
      "Epoch 650/900\n",
      "5/5 - 0s - loss: 0.0196 - val_loss: 0.0297 - 152ms/epoch - 30ms/step\n",
      "Epoch 651/900\n",
      "5/5 - 0s - loss: 0.0198 - val_loss: 0.0260 - 143ms/epoch - 29ms/step\n",
      "Epoch 652/900\n",
      "5/5 - 0s - loss: 0.0187 - val_loss: 0.0246 - 147ms/epoch - 29ms/step\n",
      "Epoch 653/900\n",
      "5/5 - 0s - loss: 0.0179 - val_loss: 0.0247 - 153ms/epoch - 31ms/step\n",
      "Epoch 654/900\n",
      "5/5 - 0s - loss: 0.0180 - val_loss: 0.0240 - 151ms/epoch - 30ms/step\n",
      "Epoch 655/900\n",
      "5/5 - 0s - loss: 0.0178 - val_loss: 0.0242 - 144ms/epoch - 29ms/step\n",
      "Epoch 656/900\n",
      "5/5 - 0s - loss: 0.0181 - val_loss: 0.0240 - 157ms/epoch - 31ms/step\n",
      "Epoch 657/900\n",
      "5/5 - 0s - loss: 0.0180 - val_loss: 0.0244 - 150ms/epoch - 30ms/step\n",
      "Epoch 658/900\n",
      "5/5 - 0s - loss: 0.0181 - val_loss: 0.0241 - 156ms/epoch - 31ms/step\n",
      "Epoch 659/900\n",
      "5/5 - 0s - loss: 0.0179 - val_loss: 0.0240 - 150ms/epoch - 30ms/step\n",
      "Epoch 660/900\n",
      "5/5 - 0s - loss: 0.0179 - val_loss: 0.0244 - 150ms/epoch - 30ms/step\n",
      "Epoch 661/900\n",
      "5/5 - 0s - loss: 0.0179 - val_loss: 0.0240 - 151ms/epoch - 30ms/step\n",
      "Epoch 662/900\n",
      "5/5 - 0s - loss: 0.0180 - val_loss: 0.0242 - 150ms/epoch - 30ms/step\n",
      "Epoch 663/900\n",
      "5/5 - 0s - loss: 0.0179 - val_loss: 0.0244 - 146ms/epoch - 29ms/step\n",
      "Epoch 664/900\n",
      "5/5 - 0s - loss: 0.0180 - val_loss: 0.0240 - 153ms/epoch - 31ms/step\n",
      "Epoch 665/900\n",
      "5/5 - 0s - loss: 0.0184 - val_loss: 0.0255 - 174ms/epoch - 35ms/step\n",
      "Epoch 666/900\n",
      "5/5 - 0s - loss: 0.0185 - val_loss: 0.0248 - 158ms/epoch - 32ms/step\n",
      "Epoch 667/900\n",
      "5/5 - 0s - loss: 0.0181 - val_loss: 0.0247 - 163ms/epoch - 33ms/step\n",
      "Epoch 668/900\n",
      "5/5 - 0s - loss: 0.0183 - val_loss: 0.0246 - 165ms/epoch - 33ms/step\n",
      "Epoch 669/900\n",
      "5/5 - 0s - loss: 0.0183 - val_loss: 0.0240 - 164ms/epoch - 33ms/step\n",
      "Epoch 670/900\n",
      "5/5 - 0s - loss: 0.0182 - val_loss: 0.0253 - 194ms/epoch - 39ms/step\n",
      "Epoch 671/900\n",
      "5/5 - 0s - loss: 0.0183 - val_loss: 0.0246 - 162ms/epoch - 32ms/step\n",
      "Epoch 672/900\n",
      "5/5 - 0s - loss: 0.0185 - val_loss: 0.0260 - 146ms/epoch - 29ms/step\n",
      "Epoch 673/900\n",
      "5/5 - 0s - loss: 0.0186 - val_loss: 0.0268 - 157ms/epoch - 31ms/step\n",
      "Epoch 674/900\n",
      "5/5 - 0s - loss: 0.0190 - val_loss: 0.0242 - 146ms/epoch - 29ms/step\n",
      "Epoch 675/900\n",
      "5/5 - 0s - loss: 0.0180 - val_loss: 0.0242 - 174ms/epoch - 35ms/step\n",
      "Epoch 676/900\n",
      "5/5 - 0s - loss: 0.0178 - val_loss: 0.0241 - 150ms/epoch - 30ms/step\n",
      "Epoch 677/900\n",
      "5/5 - 0s - loss: 0.0178 - val_loss: 0.0243 - 150ms/epoch - 30ms/step\n",
      "Epoch 678/900\n",
      "5/5 - 0s - loss: 0.0180 - val_loss: 0.0241 - 146ms/epoch - 29ms/step\n",
      "Epoch 679/900\n",
      "5/5 - 0s - loss: 0.0179 - val_loss: 0.0239 - 149ms/epoch - 30ms/step\n",
      "Epoch 680/900\n",
      "5/5 - 0s - loss: 0.0178 - val_loss: 0.0247 - 146ms/epoch - 29ms/step\n",
      "Epoch 681/900\n",
      "5/5 - 0s - loss: 0.0180 - val_loss: 0.0241 - 145ms/epoch - 29ms/step\n",
      "Epoch 682/900\n",
      "5/5 - 0s - loss: 0.0179 - val_loss: 0.0243 - 147ms/epoch - 29ms/step\n",
      "Epoch 683/900\n",
      "5/5 - 0s - loss: 0.0179 - val_loss: 0.0253 - 144ms/epoch - 29ms/step\n",
      "Epoch 684/900\n",
      "5/5 - 0s - loss: 0.0182 - val_loss: 0.0243 - 145ms/epoch - 29ms/step\n",
      "Epoch 685/900\n",
      "5/5 - 0s - loss: 0.0182 - val_loss: 0.0239 - 139ms/epoch - 28ms/step\n",
      "Epoch 686/900\n",
      "5/5 - 0s - loss: 0.0181 - val_loss: 0.0245 - 158ms/epoch - 32ms/step\n",
      "Epoch 687/900\n",
      "5/5 - 0s - loss: 0.0182 - val_loss: 0.0242 - 169ms/epoch - 34ms/step\n",
      "Epoch 688/900\n",
      "5/5 - 0s - loss: 0.0181 - val_loss: 0.0247 - 145ms/epoch - 29ms/step\n",
      "Epoch 689/900\n",
      "5/5 - 0s - loss: 0.0179 - val_loss: 0.0240 - 166ms/epoch - 33ms/step\n",
      "Epoch 690/900\n",
      "5/5 - 0s - loss: 0.0177 - val_loss: 0.0251 - 166ms/epoch - 33ms/step\n",
      "Epoch 691/900\n",
      "5/5 - 0s - loss: 0.0179 - val_loss: 0.0240 - 161ms/epoch - 32ms/step\n",
      "Epoch 692/900\n",
      "5/5 - 0s - loss: 0.0177 - val_loss: 0.0239 - 170ms/epoch - 34ms/step\n",
      "Epoch 693/900\n",
      "5/5 - 0s - loss: 0.0177 - val_loss: 0.0240 - 142ms/epoch - 28ms/step\n",
      "Epoch 694/900\n",
      "5/5 - 0s - loss: 0.0177 - val_loss: 0.0240 - 153ms/epoch - 31ms/step\n",
      "Epoch 695/900\n",
      "5/5 - 0s - loss: 0.0177 - val_loss: 0.0239 - 192ms/epoch - 38ms/step\n",
      "Epoch 696/900\n",
      "5/5 - 0s - loss: 0.0177 - val_loss: 0.0238 - 161ms/epoch - 32ms/step\n",
      "Epoch 697/900\n",
      "5/5 - 0s - loss: 0.0178 - val_loss: 0.0238 - 178ms/epoch - 36ms/step\n",
      "Epoch 698/900\n",
      "5/5 - 0s - loss: 0.0177 - val_loss: 0.0243 - 171ms/epoch - 34ms/step\n",
      "Epoch 699/900\n",
      "5/5 - 0s - loss: 0.0180 - val_loss: 0.0244 - 155ms/epoch - 31ms/step\n",
      "Epoch 700/900\n",
      "5/5 - 0s - loss: 0.0178 - val_loss: 0.0243 - 155ms/epoch - 31ms/step\n",
      "Epoch 701/900\n",
      "5/5 - 0s - loss: 0.0181 - val_loss: 0.0247 - 153ms/epoch - 31ms/step\n",
      "Epoch 702/900\n",
      "5/5 - 0s - loss: 0.0182 - val_loss: 0.0238 - 152ms/epoch - 30ms/step\n",
      "Epoch 703/900\n",
      "5/5 - 0s - loss: 0.0180 - val_loss: 0.0256 - 151ms/epoch - 30ms/step\n",
      "Epoch 704/900\n",
      "5/5 - 0s - loss: 0.0179 - val_loss: 0.0238 - 149ms/epoch - 30ms/step\n",
      "Epoch 705/900\n",
      "5/5 - 0s - loss: 0.0178 - val_loss: 0.0246 - 151ms/epoch - 30ms/step\n",
      "Epoch 706/900\n",
      "5/5 - 0s - loss: 0.0182 - val_loss: 0.0239 - 147ms/epoch - 29ms/step\n",
      "Epoch 707/900\n",
      "5/5 - 0s - loss: 0.0183 - val_loss: 0.0254 - 145ms/epoch - 29ms/step\n",
      "Epoch 708/900\n",
      "5/5 - 0s - loss: 0.0183 - val_loss: 0.0264 - 153ms/epoch - 31ms/step\n",
      "Epoch 709/900\n",
      "5/5 - 0s - loss: 0.0193 - val_loss: 0.0268 - 151ms/epoch - 30ms/step\n",
      "Epoch 710/900\n",
      "5/5 - 0s - loss: 0.0192 - val_loss: 0.0243 - 150ms/epoch - 30ms/step\n",
      "Epoch 711/900\n",
      "5/5 - 0s - loss: 0.0185 - val_loss: 0.0270 - 148ms/epoch - 30ms/step\n",
      "Epoch 712/900\n",
      "5/5 - 0s - loss: 0.0189 - val_loss: 0.0261 - 148ms/epoch - 30ms/step\n",
      "Epoch 713/900\n",
      "5/5 - 0s - loss: 0.0188 - val_loss: 0.0240 - 150ms/epoch - 30ms/step\n",
      "Epoch 714/900\n",
      "5/5 - 0s - loss: 0.0179 - val_loss: 0.0240 - 146ms/epoch - 29ms/step\n",
      "Epoch 715/900\n",
      "5/5 - 0s - loss: 0.0178 - val_loss: 0.0240 - 149ms/epoch - 30ms/step\n",
      "Epoch 716/900\n",
      "5/5 - 0s - loss: 0.0176 - val_loss: 0.0238 - 149ms/epoch - 30ms/step\n",
      "Epoch 717/900\n",
      "5/5 - 0s - loss: 0.0176 - val_loss: 0.0239 - 150ms/epoch - 30ms/step\n",
      "Epoch 718/900\n",
      "5/5 - 0s - loss: 0.0176 - val_loss: 0.0244 - 143ms/epoch - 29ms/step\n",
      "Epoch 719/900\n",
      "5/5 - 0s - loss: 0.0177 - val_loss: 0.0237 - 147ms/epoch - 29ms/step\n",
      "Epoch 720/900\n",
      "5/5 - 0s - loss: 0.0178 - val_loss: 0.0252 - 147ms/epoch - 29ms/step\n",
      "Epoch 721/900\n",
      "5/5 - 0s - loss: 0.0180 - val_loss: 0.0239 - 146ms/epoch - 29ms/step\n",
      "Epoch 722/900\n",
      "5/5 - 0s - loss: 0.0177 - val_loss: 0.0239 - 148ms/epoch - 30ms/step\n",
      "Epoch 723/900\n",
      "5/5 - 0s - loss: 0.0177 - val_loss: 0.0239 - 153ms/epoch - 31ms/step\n",
      "Epoch 724/900\n",
      "5/5 - 0s - loss: 0.0176 - val_loss: 0.0242 - 155ms/epoch - 31ms/step\n",
      "Epoch 725/900\n",
      "5/5 - 0s - loss: 0.0177 - val_loss: 0.0239 - 152ms/epoch - 30ms/step\n",
      "Epoch 726/900\n",
      "5/5 - 0s - loss: 0.0177 - val_loss: 0.0238 - 151ms/epoch - 30ms/step\n",
      "Epoch 727/900\n",
      "5/5 - 0s - loss: 0.0176 - val_loss: 0.0249 - 148ms/epoch - 30ms/step\n",
      "Epoch 728/900\n",
      "5/5 - 0s - loss: 0.0179 - val_loss: 0.0240 - 149ms/epoch - 30ms/step\n",
      "Epoch 729/900\n",
      "5/5 - 0s - loss: 0.0176 - val_loss: 0.0241 - 149ms/epoch - 30ms/step\n",
      "Epoch 730/900\n",
      "5/5 - 0s - loss: 0.0178 - val_loss: 0.0248 - 150ms/epoch - 30ms/step\n",
      "Epoch 731/900\n",
      "5/5 - 0s - loss: 0.0180 - val_loss: 0.0244 - 151ms/epoch - 30ms/step\n",
      "Epoch 732/900\n",
      "5/5 - 0s - loss: 0.0184 - val_loss: 0.0253 - 148ms/epoch - 30ms/step\n",
      "Epoch 733/900\n",
      "5/5 - 0s - loss: 0.0179 - val_loss: 0.0239 - 150ms/epoch - 30ms/step\n",
      "Epoch 734/900\n",
      "5/5 - 0s - loss: 0.0179 - val_loss: 0.0237 - 145ms/epoch - 29ms/step\n",
      "Epoch 735/900\n",
      "5/5 - 0s - loss: 0.0177 - val_loss: 0.0243 - 152ms/epoch - 30ms/step\n",
      "Epoch 736/900\n",
      "5/5 - 0s - loss: 0.0177 - val_loss: 0.0237 - 153ms/epoch - 31ms/step\n",
      "Epoch 737/900\n",
      "5/5 - 0s - loss: 0.0176 - val_loss: 0.0249 - 149ms/epoch - 30ms/step\n",
      "Epoch 738/900\n",
      "5/5 - 0s - loss: 0.0179 - val_loss: 0.0243 - 152ms/epoch - 30ms/step\n",
      "Epoch 739/900\n",
      "5/5 - 0s - loss: 0.0176 - val_loss: 0.0245 - 152ms/epoch - 30ms/step\n",
      "Epoch 740/900\n",
      "5/5 - 0s - loss: 0.0177 - val_loss: 0.0239 - 150ms/epoch - 30ms/step\n",
      "Epoch 741/900\n",
      "5/5 - 0s - loss: 0.0179 - val_loss: 0.0243 - 143ms/epoch - 29ms/step\n",
      "Epoch 742/900\n",
      "5/5 - 0s - loss: 0.0179 - val_loss: 0.0238 - 153ms/epoch - 31ms/step\n",
      "Epoch 743/900\n",
      "5/5 - 0s - loss: 0.0176 - val_loss: 0.0247 - 177ms/epoch - 35ms/step\n",
      "Epoch 744/900\n",
      "5/5 - 0s - loss: 0.0177 - val_loss: 0.0237 - 150ms/epoch - 30ms/step\n",
      "Epoch 745/900\n",
      "5/5 - 0s - loss: 0.0176 - val_loss: 0.0241 - 150ms/epoch - 30ms/step\n",
      "Epoch 746/900\n",
      "5/5 - 0s - loss: 0.0176 - val_loss: 0.0240 - 149ms/epoch - 30ms/step\n",
      "Epoch 747/900\n",
      "5/5 - 0s - loss: 0.0179 - val_loss: 0.0243 - 145ms/epoch - 29ms/step\n",
      "Epoch 748/900\n",
      "5/5 - 0s - loss: 0.0181 - val_loss: 0.0259 - 149ms/epoch - 30ms/step\n",
      "Epoch 749/900\n",
      "5/5 - 0s - loss: 0.0182 - val_loss: 0.0251 - 153ms/epoch - 31ms/step\n",
      "Epoch 750/900\n",
      "5/5 - 0s - loss: 0.0183 - val_loss: 0.0248 - 150ms/epoch - 30ms/step\n",
      "Epoch 751/900\n",
      "5/5 - 0s - loss: 0.0179 - val_loss: 0.0238 - 150ms/epoch - 30ms/step\n",
      "Epoch 752/900\n",
      "5/5 - 0s - loss: 0.0179 - val_loss: 0.0238 - 149ms/epoch - 30ms/step\n",
      "Epoch 753/900\n",
      "5/5 - 0s - loss: 0.0177 - val_loss: 0.0247 - 153ms/epoch - 31ms/step\n",
      "Epoch 754/900\n",
      "5/5 - 0s - loss: 0.0179 - val_loss: 0.0237 - 151ms/epoch - 30ms/step\n",
      "Epoch 755/900\n",
      "5/5 - 0s - loss: 0.0177 - val_loss: 0.0241 - 152ms/epoch - 30ms/step\n",
      "Epoch 756/900\n",
      "5/5 - 0s - loss: 0.0177 - val_loss: 0.0243 - 152ms/epoch - 30ms/step\n",
      "Epoch 757/900\n",
      "5/5 - 0s - loss: 0.0177 - val_loss: 0.0246 - 146ms/epoch - 29ms/step\n",
      "Epoch 758/900\n",
      "5/5 - 0s - loss: 0.0176 - val_loss: 0.0238 - 152ms/epoch - 30ms/step\n",
      "Epoch 759/900\n",
      "5/5 - 0s - loss: 0.0176 - val_loss: 0.0236 - 149ms/epoch - 30ms/step\n",
      "Epoch 760/900\n",
      "5/5 - 0s - loss: 0.0175 - val_loss: 0.0237 - 150ms/epoch - 30ms/step\n",
      "Epoch 761/900\n",
      "5/5 - 0s - loss: 0.0175 - val_loss: 0.0237 - 147ms/epoch - 29ms/step\n",
      "Epoch 762/900\n",
      "5/5 - 0s - loss: 0.0175 - val_loss: 0.0239 - 146ms/epoch - 29ms/step\n",
      "Epoch 763/900\n",
      "5/5 - 0s - loss: 0.0177 - val_loss: 0.0243 - 150ms/epoch - 30ms/step\n",
      "Epoch 764/900\n",
      "5/5 - 0s - loss: 0.0177 - val_loss: 0.0237 - 147ms/epoch - 29ms/step\n",
      "Epoch 765/900\n",
      "5/5 - 0s - loss: 0.0176 - val_loss: 0.0242 - 149ms/epoch - 30ms/step\n",
      "Epoch 766/900\n",
      "5/5 - 0s - loss: 0.0179 - val_loss: 0.0247 - 147ms/epoch - 29ms/step\n",
      "Epoch 767/900\n",
      "5/5 - 0s - loss: 0.0180 - val_loss: 0.0243 - 146ms/epoch - 29ms/step\n",
      "Epoch 768/900\n",
      "5/5 - 0s - loss: 0.0178 - val_loss: 0.0239 - 147ms/epoch - 29ms/step\n",
      "Epoch 769/900\n",
      "5/5 - 0s - loss: 0.0176 - val_loss: 0.0240 - 148ms/epoch - 30ms/step\n",
      "Epoch 770/900\n",
      "5/5 - 0s - loss: 0.0175 - val_loss: 0.0238 - 146ms/epoch - 29ms/step\n",
      "Epoch 771/900\n",
      "5/5 - 0s - loss: 0.0176 - val_loss: 0.0239 - 149ms/epoch - 30ms/step\n",
      "Epoch 772/900\n",
      "5/5 - 0s - loss: 0.0176 - val_loss: 0.0237 - 147ms/epoch - 29ms/step\n",
      "Epoch 773/900\n",
      "5/5 - 0s - loss: 0.0176 - val_loss: 0.0235 - 146ms/epoch - 29ms/step\n",
      "Epoch 774/900\n",
      "5/5 - 0s - loss: 0.0176 - val_loss: 0.0237 - 148ms/epoch - 30ms/step\n",
      "Epoch 775/900\n",
      "5/5 - 0s - loss: 0.0175 - val_loss: 0.0239 - 149ms/epoch - 30ms/step\n",
      "Epoch 776/900\n",
      "5/5 - 0s - loss: 0.0176 - val_loss: 0.0240 - 151ms/epoch - 30ms/step\n",
      "Epoch 777/900\n",
      "5/5 - 0s - loss: 0.0176 - val_loss: 0.0238 - 150ms/epoch - 30ms/step\n",
      "Epoch 778/900\n",
      "5/5 - 0s - loss: 0.0177 - val_loss: 0.0236 - 153ms/epoch - 31ms/step\n",
      "Epoch 779/900\n",
      "5/5 - 0s - loss: 0.0178 - val_loss: 0.0237 - 148ms/epoch - 30ms/step\n",
      "Epoch 780/900\n",
      "5/5 - 0s - loss: 0.0176 - val_loss: 0.0236 - 149ms/epoch - 30ms/step\n",
      "Epoch 781/900\n",
      "5/5 - 0s - loss: 0.0177 - val_loss: 0.0238 - 148ms/epoch - 30ms/step\n",
      "Epoch 782/900\n",
      "5/5 - 0s - loss: 0.0175 - val_loss: 0.0240 - 148ms/epoch - 30ms/step\n",
      "Epoch 783/900\n",
      "5/5 - 0s - loss: 0.0178 - val_loss: 0.0241 - 149ms/epoch - 30ms/step\n",
      "Epoch 784/900\n",
      "5/5 - 0s - loss: 0.0179 - val_loss: 0.0239 - 150ms/epoch - 30ms/step\n",
      "Epoch 785/900\n",
      "5/5 - 0s - loss: 0.0175 - val_loss: 0.0237 - 150ms/epoch - 30ms/step\n",
      "Epoch 786/900\n",
      "5/5 - 0s - loss: 0.0175 - val_loss: 0.0235 - 153ms/epoch - 31ms/step\n",
      "Epoch 787/900\n",
      "5/5 - 0s - loss: 0.0174 - val_loss: 0.0235 - 149ms/epoch - 30ms/step\n",
      "Epoch 788/900\n",
      "5/5 - 0s - loss: 0.0175 - val_loss: 0.0262 - 150ms/epoch - 30ms/step\n",
      "Epoch 789/900\n",
      "5/5 - 0s - loss: 0.0183 - val_loss: 0.0245 - 149ms/epoch - 30ms/step\n",
      "Epoch 790/900\n",
      "5/5 - 0s - loss: 0.0182 - val_loss: 0.0246 - 150ms/epoch - 30ms/step\n",
      "Epoch 791/900\n",
      "5/5 - 0s - loss: 0.0180 - val_loss: 0.0257 - 145ms/epoch - 29ms/step\n",
      "Epoch 792/900\n",
      "5/5 - 0s - loss: 0.0182 - val_loss: 0.0243 - 147ms/epoch - 29ms/step\n",
      "Epoch 793/900\n",
      "5/5 - 0s - loss: 0.0181 - val_loss: 0.0248 - 151ms/epoch - 30ms/step\n",
      "Epoch 794/900\n",
      "5/5 - 0s - loss: 0.0180 - val_loss: 0.0252 - 148ms/epoch - 30ms/step\n",
      "Epoch 795/900\n",
      "5/5 - 0s - loss: 0.0183 - val_loss: 0.0242 - 146ms/epoch - 29ms/step\n",
      "Epoch 796/900\n",
      "5/5 - 0s - loss: 0.0179 - val_loss: 0.0259 - 145ms/epoch - 29ms/step\n",
      "Epoch 797/900\n",
      "5/5 - 0s - loss: 0.0180 - val_loss: 0.0235 - 149ms/epoch - 30ms/step\n",
      "Epoch 798/900\n",
      "5/5 - 0s - loss: 0.0175 - val_loss: 0.0235 - 149ms/epoch - 30ms/step\n",
      "Epoch 799/900\n",
      "5/5 - 0s - loss: 0.0174 - val_loss: 0.0237 - 145ms/epoch - 29ms/step\n",
      "Epoch 800/900\n",
      "5/5 - 0s - loss: 0.0173 - val_loss: 0.0236 - 149ms/epoch - 30ms/step\n",
      "Epoch 801/900\n",
      "5/5 - 0s - loss: 0.0177 - val_loss: 0.0237 - 147ms/epoch - 29ms/step\n",
      "Epoch 802/900\n",
      "5/5 - 0s - loss: 0.0175 - val_loss: 0.0243 - 150ms/epoch - 30ms/step\n",
      "Epoch 803/900\n",
      "5/5 - 0s - loss: 0.0177 - val_loss: 0.0236 - 150ms/epoch - 30ms/step\n",
      "Epoch 804/900\n",
      "5/5 - 0s - loss: 0.0175 - val_loss: 0.0246 - 146ms/epoch - 29ms/step\n",
      "Epoch 805/900\n",
      "5/5 - 0s - loss: 0.0179 - val_loss: 0.0240 - 155ms/epoch - 31ms/step\n",
      "Epoch 806/900\n",
      "5/5 - 0s - loss: 0.0179 - val_loss: 0.0239 - 150ms/epoch - 30ms/step\n",
      "Epoch 807/900\n",
      "5/5 - 0s - loss: 0.0175 - val_loss: 0.0235 - 153ms/epoch - 31ms/step\n",
      "Epoch 808/900\n",
      "5/5 - 0s - loss: 0.0173 - val_loss: 0.0236 - 150ms/epoch - 30ms/step\n",
      "Epoch 809/900\n",
      "5/5 - 0s - loss: 0.0173 - val_loss: 0.0234 - 153ms/epoch - 31ms/step\n",
      "Epoch 810/900\n",
      "5/5 - 0s - loss: 0.0174 - val_loss: 0.0235 - 147ms/epoch - 29ms/step\n",
      "Epoch 811/900\n",
      "5/5 - 0s - loss: 0.0174 - val_loss: 0.0235 - 149ms/epoch - 30ms/step\n",
      "Epoch 812/900\n",
      "5/5 - 0s - loss: 0.0174 - val_loss: 0.0237 - 151ms/epoch - 30ms/step\n",
      "Epoch 813/900\n",
      "5/5 - 0s - loss: 0.0175 - val_loss: 0.0236 - 149ms/epoch - 30ms/step\n",
      "Epoch 814/900\n",
      "5/5 - 0s - loss: 0.0178 - val_loss: 0.0248 - 147ms/epoch - 29ms/step\n",
      "Epoch 815/900\n",
      "5/5 - 0s - loss: 0.0181 - val_loss: 0.0240 - 153ms/epoch - 31ms/step\n",
      "Epoch 816/900\n",
      "5/5 - 0s - loss: 0.0184 - val_loss: 0.0246 - 148ms/epoch - 30ms/step\n",
      "Epoch 817/900\n",
      "5/5 - 0s - loss: 0.0181 - val_loss: 0.0242 - 148ms/epoch - 30ms/step\n",
      "Epoch 818/900\n",
      "5/5 - 0s - loss: 0.0181 - val_loss: 0.0260 - 150ms/epoch - 30ms/step\n",
      "Epoch 819/900\n",
      "5/5 - 0s - loss: 0.0182 - val_loss: 0.0242 - 148ms/epoch - 30ms/step\n",
      "Epoch 820/900\n",
      "5/5 - 0s - loss: 0.0177 - val_loss: 0.0235 - 145ms/epoch - 29ms/step\n",
      "Epoch 821/900\n",
      "5/5 - 0s - loss: 0.0175 - val_loss: 0.0238 - 151ms/epoch - 30ms/step\n",
      "Epoch 822/900\n",
      "5/5 - 0s - loss: 0.0176 - val_loss: 0.0241 - 147ms/epoch - 29ms/step\n",
      "Epoch 823/900\n",
      "5/5 - 0s - loss: 0.0175 - val_loss: 0.0235 - 146ms/epoch - 29ms/step\n",
      "Epoch 824/900\n",
      "5/5 - 0s - loss: 0.0176 - val_loss: 0.0246 - 150ms/epoch - 30ms/step\n",
      "Epoch 825/900\n",
      "5/5 - 0s - loss: 0.0177 - val_loss: 0.0236 - 152ms/epoch - 30ms/step\n",
      "Epoch 826/900\n",
      "5/5 - 0s - loss: 0.0173 - val_loss: 0.0242 - 147ms/epoch - 29ms/step\n",
      "Epoch 827/900\n",
      "5/5 - 0s - loss: 0.0175 - val_loss: 0.0239 - 147ms/epoch - 29ms/step\n",
      "Epoch 828/900\n",
      "5/5 - 0s - loss: 0.0174 - val_loss: 0.0237 - 147ms/epoch - 29ms/step\n",
      "Epoch 829/900\n",
      "5/5 - 0s - loss: 0.0174 - val_loss: 0.0236 - 152ms/epoch - 30ms/step\n",
      "Epoch 830/900\n",
      "5/5 - 0s - loss: 0.0177 - val_loss: 0.0250 - 150ms/epoch - 30ms/step\n",
      "Epoch 831/900\n",
      "5/5 - 0s - loss: 0.0181 - val_loss: 0.0240 - 149ms/epoch - 30ms/step\n",
      "Epoch 832/900\n",
      "5/5 - 0s - loss: 0.0176 - val_loss: 0.0239 - 148ms/epoch - 30ms/step\n",
      "Epoch 833/900\n",
      "5/5 - 0s - loss: 0.0175 - val_loss: 0.0234 - 151ms/epoch - 30ms/step\n",
      "Epoch 834/900\n",
      "5/5 - 0s - loss: 0.0176 - val_loss: 0.0246 - 147ms/epoch - 29ms/step\n",
      "Epoch 835/900\n",
      "5/5 - 0s - loss: 0.0177 - val_loss: 0.0236 - 151ms/epoch - 30ms/step\n",
      "Epoch 836/900\n",
      "5/5 - 0s - loss: 0.0175 - val_loss: 0.0238 - 151ms/epoch - 30ms/step\n",
      "Epoch 837/900\n",
      "5/5 - 0s - loss: 0.0178 - val_loss: 0.0245 - 153ms/epoch - 31ms/step\n",
      "Epoch 838/900\n",
      "5/5 - 0s - loss: 0.0176 - val_loss: 0.0234 - 157ms/epoch - 31ms/step\n",
      "Epoch 839/900\n",
      "5/5 - 0s - loss: 0.0173 - val_loss: 0.0246 - 157ms/epoch - 31ms/step\n",
      "Epoch 840/900\n",
      "5/5 - 0s - loss: 0.0178 - val_loss: 0.0235 - 156ms/epoch - 31ms/step\n",
      "Epoch 841/900\n",
      "5/5 - 0s - loss: 0.0175 - val_loss: 0.0239 - 143ms/epoch - 29ms/step\n",
      "Epoch 842/900\n",
      "5/5 - 0s - loss: 0.0177 - val_loss: 0.0234 - 145ms/epoch - 29ms/step\n",
      "Epoch 843/900\n",
      "5/5 - 0s - loss: 0.0176 - val_loss: 0.0242 - 143ms/epoch - 29ms/step\n",
      "Epoch 844/900\n",
      "5/5 - 0s - loss: 0.0176 - val_loss: 0.0234 - 141ms/epoch - 28ms/step\n",
      "Epoch 845/900\n",
      "5/5 - 0s - loss: 0.0174 - val_loss: 0.0234 - 138ms/epoch - 28ms/step\n",
      "Epoch 846/900\n",
      "5/5 - 0s - loss: 0.0172 - val_loss: 0.0238 - 141ms/epoch - 28ms/step\n",
      "Epoch 847/900\n",
      "5/5 - 0s - loss: 0.0175 - val_loss: 0.0237 - 139ms/epoch - 28ms/step\n",
      "Epoch 848/900\n",
      "5/5 - 0s - loss: 0.0176 - val_loss: 0.0233 - 143ms/epoch - 29ms/step\n",
      "Epoch 849/900\n",
      "5/5 - 0s - loss: 0.0175 - val_loss: 0.0239 - 140ms/epoch - 28ms/step\n",
      "Epoch 850/900\n",
      "5/5 - 0s - loss: 0.0175 - val_loss: 0.0233 - 137ms/epoch - 27ms/step\n",
      "Epoch 851/900\n",
      "5/5 - 0s - loss: 0.0173 - val_loss: 0.0244 - 141ms/epoch - 28ms/step\n",
      "Epoch 852/900\n",
      "5/5 - 0s - loss: 0.0173 - val_loss: 0.0234 - 139ms/epoch - 28ms/step\n",
      "Epoch 853/900\n",
      "5/5 - 0s - loss: 0.0172 - val_loss: 0.0234 - 142ms/epoch - 28ms/step\n",
      "Epoch 854/900\n",
      "5/5 - 0s - loss: 0.0172 - val_loss: 0.0235 - 140ms/epoch - 28ms/step\n",
      "Epoch 855/900\n",
      "5/5 - 0s - loss: 0.0172 - val_loss: 0.0233 - 159ms/epoch - 32ms/step\n",
      "Epoch 856/900\n",
      "5/5 - 0s - loss: 0.0173 - val_loss: 0.0234 - 176ms/epoch - 35ms/step\n",
      "Epoch 857/900\n",
      "5/5 - 0s - loss: 0.0172 - val_loss: 0.0234 - 148ms/epoch - 30ms/step\n",
      "Epoch 858/900\n",
      "5/5 - 0s - loss: 0.0172 - val_loss: 0.0233 - 149ms/epoch - 30ms/step\n",
      "Epoch 859/900\n",
      "5/5 - 0s - loss: 0.0172 - val_loss: 0.0235 - 145ms/epoch - 29ms/step\n",
      "Epoch 860/900\n",
      "5/5 - 0s - loss: 0.0172 - val_loss: 0.0234 - 144ms/epoch - 29ms/step\n",
      "Epoch 861/900\n",
      "5/5 - 0s - loss: 0.0175 - val_loss: 0.0234 - 146ms/epoch - 29ms/step\n",
      "Epoch 862/900\n",
      "5/5 - 0s - loss: 0.0173 - val_loss: 0.0235 - 145ms/epoch - 29ms/step\n",
      "Epoch 863/900\n",
      "5/5 - 0s - loss: 0.0172 - val_loss: 0.0235 - 140ms/epoch - 28ms/step\n",
      "Epoch 864/900\n",
      "5/5 - 0s - loss: 0.0172 - val_loss: 0.0235 - 147ms/epoch - 29ms/step\n",
      "Epoch 865/900\n",
      "5/5 - 0s - loss: 0.0172 - val_loss: 0.0236 - 157ms/epoch - 31ms/step\n",
      "Epoch 866/900\n",
      "5/5 - 0s - loss: 0.0172 - val_loss: 0.0235 - 140ms/epoch - 28ms/step\n",
      "Epoch 867/900\n",
      "5/5 - 0s - loss: 0.0172 - val_loss: 0.0233 - 140ms/epoch - 28ms/step\n",
      "Epoch 868/900\n",
      "5/5 - 0s - loss: 0.0175 - val_loss: 0.0237 - 137ms/epoch - 27ms/step\n",
      "Epoch 869/900\n",
      "5/5 - 0s - loss: 0.0179 - val_loss: 0.0254 - 149ms/epoch - 30ms/step\n",
      "Epoch 870/900\n",
      "5/5 - 0s - loss: 0.0178 - val_loss: 0.0244 - 158ms/epoch - 32ms/step\n",
      "Epoch 871/900\n",
      "5/5 - 0s - loss: 0.0176 - val_loss: 0.0241 - 140ms/epoch - 28ms/step\n",
      "Epoch 872/900\n",
      "5/5 - 0s - loss: 0.0176 - val_loss: 0.0242 - 140ms/epoch - 28ms/step\n",
      "Epoch 873/900\n",
      "5/5 - 0s - loss: 0.0175 - val_loss: 0.0239 - 138ms/epoch - 28ms/step\n",
      "Epoch 874/900\n",
      "5/5 - 0s - loss: 0.0173 - val_loss: 0.0245 - 138ms/epoch - 28ms/step\n",
      "Epoch 875/900\n",
      "5/5 - 0s - loss: 0.0174 - val_loss: 0.0238 - 142ms/epoch - 28ms/step\n",
      "Epoch 876/900\n",
      "5/5 - 0s - loss: 0.0175 - val_loss: 0.0236 - 140ms/epoch - 28ms/step\n",
      "Epoch 877/900\n",
      "5/5 - 0s - loss: 0.0175 - val_loss: 0.0241 - 138ms/epoch - 28ms/step\n",
      "Epoch 878/900\n",
      "5/5 - 0s - loss: 0.0173 - val_loss: 0.0234 - 136ms/epoch - 27ms/step\n",
      "Epoch 879/900\n",
      "5/5 - 0s - loss: 0.0172 - val_loss: 0.0233 - 139ms/epoch - 28ms/step\n",
      "Epoch 880/900\n",
      "5/5 - 0s - loss: 0.0173 - val_loss: 0.0235 - 141ms/epoch - 28ms/step\n",
      "Epoch 881/900\n",
      "5/5 - 0s - loss: 0.0174 - val_loss: 0.0238 - 136ms/epoch - 27ms/step\n",
      "Epoch 882/900\n",
      "5/5 - 0s - loss: 0.0172 - val_loss: 0.0233 - 135ms/epoch - 27ms/step\n",
      "Epoch 883/900\n",
      "5/5 - 0s - loss: 0.0172 - val_loss: 0.0234 - 142ms/epoch - 28ms/step\n",
      "Epoch 884/900\n",
      "5/5 - 0s - loss: 0.0172 - val_loss: 0.0233 - 137ms/epoch - 27ms/step\n",
      "Epoch 885/900\n",
      "5/5 - 0s - loss: 0.0172 - val_loss: 0.0233 - 141ms/epoch - 28ms/step\n",
      "Epoch 886/900\n",
      "5/5 - 0s - loss: 0.0172 - val_loss: 0.0235 - 139ms/epoch - 28ms/step\n",
      "Epoch 887/900\n",
      "5/5 - 0s - loss: 0.0171 - val_loss: 0.0233 - 140ms/epoch - 28ms/step\n",
      "Epoch 888/900\n",
      "5/5 - 0s - loss: 0.0171 - val_loss: 0.0232 - 141ms/epoch - 28ms/step\n",
      "Epoch 889/900\n",
      "5/5 - 0s - loss: 0.0173 - val_loss: 0.0233 - 146ms/epoch - 29ms/step\n",
      "Epoch 890/900\n",
      "5/5 - 0s - loss: 0.0172 - val_loss: 0.0235 - 149ms/epoch - 30ms/step\n",
      "Epoch 891/900\n",
      "5/5 - 0s - loss: 0.0172 - val_loss: 0.0233 - 147ms/epoch - 29ms/step\n",
      "Epoch 892/900\n",
      "5/5 - 0s - loss: 0.0172 - val_loss: 0.0244 - 147ms/epoch - 29ms/step\n",
      "Epoch 893/900\n",
      "5/5 - 0s - loss: 0.0174 - val_loss: 0.0233 - 149ms/epoch - 30ms/step\n",
      "Epoch 894/900\n",
      "5/5 - 0s - loss: 0.0171 - val_loss: 0.0233 - 146ms/epoch - 29ms/step\n",
      "Epoch 895/900\n",
      "5/5 - 0s - loss: 0.0171 - val_loss: 0.0232 - 140ms/epoch - 28ms/step\n",
      "Epoch 896/900\n",
      "5/5 - 0s - loss: 0.0171 - val_loss: 0.0232 - 138ms/epoch - 28ms/step\n",
      "Epoch 897/900\n",
      "5/5 - 0s - loss: 0.0172 - val_loss: 0.0234 - 145ms/epoch - 29ms/step\n",
      "Epoch 898/900\n",
      "5/5 - 0s - loss: 0.0173 - val_loss: 0.0234 - 154ms/epoch - 31ms/step\n",
      "Epoch 899/900\n",
      "5/5 - 0s - loss: 0.0173 - val_loss: 0.0239 - 146ms/epoch - 29ms/step\n",
      "Epoch 900/900\n",
      "5/5 - 0s - loss: 0.0174 - val_loss: 0.0233 - 143ms/epoch - 29ms/step\n"
     ]
    }
   ],
   "source": [
    "batch_size = 512\n",
    "epochs = 900\n",
    "patience = 30\n",
    "l2_value = 0.01\n",
    "\n",
    "## GENERATE MODEL ##\n",
    "model = build_model(input_shape=(train_data.shape[1], train_data.shape[2]), l2_value=l2_value)\n",
    "# np.expand_dims(train_data, axis=2)\n",
    "train_model(model, train_data, train_target, epochs=epochs, batch_size=batch_size, patience=patience)\n",
    "\n",
    "## LOAD MODEL ##\n",
    "# model = load_model(path_price_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[23.81999969, 23.73999977, 22.95999908, 23.60000038, 23.65999985]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler_target.inverse_transform([test_target[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([23.320194, 23.46241 , 23.330912, 23.296318, 23.178535],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_predicted_array[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "data_to_predict = test_data\n",
    "actual_prediction = test_target\n",
    "\n",
    "price_predicted_array = scaler_target.inverse_transform(model.predict(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 1-dimensional, but 2 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/andrea/Desktop/ml-finance/stock-predictor-ai/code/LSTM_multiple_predictions.ipynb Cell 8\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/andrea/Desktop/ml-finance/stock-predictor-ai/code/LSTM_multiple_predictions.ipynb#X10sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m {\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/andrea/Desktop/ml-finance/stock-predictor-ai/code/LSTM_multiple_predictions.ipynb#X10sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mMAE\u001b[39m\u001b[39m'\u001b[39m: avg_mae,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/andrea/Desktop/ml-finance/stock-predictor-ai/code/LSTM_multiple_predictions.ipynb#X10sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mMSE\u001b[39m\u001b[39m'\u001b[39m: avg_mse,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/andrea/Desktop/ml-finance/stock-predictor-ai/code/LSTM_multiple_predictions.ipynb#X10sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mR2\u001b[39m\u001b[39m'\u001b[39m: avg_r2,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/andrea/Desktop/ml-finance/stock-predictor-ai/code/LSTM_multiple_predictions.ipynb#X10sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m     }\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/andrea/Desktop/ml-finance/stock-predictor-ai/code/LSTM_multiple_predictions.ipynb#X10sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m \u001b[39m# Use this function to evaluate your predictions\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/andrea/Desktop/ml-finance/stock-predictor-ai/code/LSTM_multiple_predictions.ipynb#X10sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m evaluation_results \u001b[39m=\u001b[39m evaluate_5_day_predictions(price_predicted_array, price_actual_array)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/andrea/Desktop/ml-finance/stock-predictor-ai/code/LSTM_multiple_predictions.ipynb#X10sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mEvaluation Results:\u001b[39m\u001b[39m\"\u001b[39m, evaluation_results)\n",
      "\u001b[1;32m/home/andrea/Desktop/ml-finance/stock-predictor-ai/code/LSTM_multiple_predictions.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/andrea/Desktop/ml-finance/stock-predictor-ai/code/LSTM_multiple_predictions.ipynb#X10sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m mae_list, mse_list, rmse_list, mape_list, r2_list \u001b[39m=\u001b[39m [], [], [], [], []\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/andrea/Desktop/ml-finance/stock-predictor-ai/code/LSTM_multiple_predictions.ipynb#X10sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m5\u001b[39m):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/andrea/Desktop/ml-finance/stock-predictor-ai/code/LSTM_multiple_predictions.ipynb#X10sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     mae \u001b[39m=\u001b[39m mean_abs_error(actual[:, i], predicted[:, i])\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/andrea/Desktop/ml-finance/stock-predictor-ai/code/LSTM_multiple_predictions.ipynb#X10sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     mse \u001b[39m=\u001b[39m mean_squared_error(actual[:, i], predicted[:, i])\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/andrea/Desktop/ml-finance/stock-predictor-ai/code/LSTM_multiple_predictions.ipynb#X10sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     rmse \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msqrt(mse)\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array: array is 1-dimensional, but 2 were indexed"
     ]
    }
   ],
   "source": [
    "data_to_predict = (test_data)\n",
    "actual_prediction = test_target\n",
    "\n",
    "# TESTing: DENORMALIZE TARGET AND PREDICTIONS ##\n",
    "price_predicted_array = scaler_target.inverse_transform(model.predict(data_to_predict))\n",
    "price_actual_array = scaler_target.inverse_transform(actual_prediction).flatten()\n",
    "\n",
    "\n",
    "def evaluate_5_day_predictions(predicted, actual):\n",
    "    # Calculate metrics for each day and average\n",
    "    mae_list, mse_list, rmse_list, mape_list, r2_list = [], [], [], [], []\n",
    "    \n",
    "    for i in range(5):\n",
    "        mae = mean_absolute_error(actual[:, i], predicted[:, i])\n",
    "        mse = mean_squared_error(actual[:, i], predicted[:, i])\n",
    "        rmse = np.sqrt(mse)\n",
    "        mape = np.mean(np.abs((actual[:, i] - predicted[:, i]) / actual[:, i])) * 100\n",
    "        r2 = r2_score(actual[:, i], predicted[:, i])\n",
    "\n",
    "        mae_list.append(mae)\n",
    "        mse_list.append(mse)\n",
    "        rmse_list.append(rmse)\n",
    "        mape_list.append(mape)\n",
    "        r2_list.append(r2)\n",
    "\n",
    "    # Averaging the metrics across 5 days\n",
    "    avg_mae = np.mean(mae_list)\n",
    "    avg_mse = np.mean(mse_list)\n",
    "    avg_rmse = np.mean(rmse_list)\n",
    "    avg_mape = np.mean(mape_list)\n",
    "    avg_r2 = np.mean(r2_list)\n",
    "\n",
    "    return {\n",
    "        'MAE': avg_mae,\n",
    "        'MSE': avg_mse,\n",
    "        'RMSE': avg_rmse,\n",
    "        'MAPE': avg_mape,\n",
    "        'R2': avg_r2,\n",
    "    }\n",
    "\n",
    "# Use this function to evaluate your predictions\n",
    "evaluation_results = evaluate_5_day_predictions(price_predicted_array, price_actual_array)\n",
    "print(\"Evaluation Results:\", evaluation_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 1-dimensional, but 2 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/andrea/Desktop/ml-finance/stock-predictor-ai/code/LSTM_multiple_predictions.ipynb Cell 9\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/andrea/Desktop/ml-finance/stock-predictor-ai/code/LSTM_multiple_predictions.ipynb#X11sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     plt\u001b[39m.\u001b[39mshow()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/andrea/Desktop/ml-finance/stock-predictor-ai/code/LSTM_multiple_predictions.ipynb#X11sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# Use this function to plot your results\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/andrea/Desktop/ml-finance/stock-predictor-ai/code/LSTM_multiple_predictions.ipynb#X11sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m plot_5_day_results(price_actual_array, price_predicted_array, target_column_name)\n",
      "\u001b[1;32m/home/andrea/Desktop/ml-finance/stock-predictor-ai/code/LSTM_multiple_predictions.ipynb Cell 9\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/andrea/Desktop/ml-finance/stock-predictor-ai/code/LSTM_multiple_predictions.ipynb#X11sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m5\u001b[39m):\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/andrea/Desktop/ml-finance/stock-predictor-ai/code/LSTM_multiple_predictions.ipynb#X11sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     plt\u001b[39m.\u001b[39msubplot(\u001b[39m3\u001b[39m, \u001b[39m2\u001b[39m, i \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/andrea/Desktop/ml-finance/stock-predictor-ai/code/LSTM_multiple_predictions.ipynb#X11sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     plt\u001b[39m.\u001b[39mplot(actual[:, i], label\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mActual Day \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(i \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m))\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/andrea/Desktop/ml-finance/stock-predictor-ai/code/LSTM_multiple_predictions.ipynb#X11sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     plt\u001b[39m.\u001b[39mplot(predicted[:, i], label\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mPredicted Day \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(i \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m))\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/andrea/Desktop/ml-finance/stock-predictor-ai/code/LSTM_multiple_predictions.ipynb#X11sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     plt\u001b[39m.\u001b[39mtitle(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mcolumn_name\u001b[39m}\u001b[39;00m\u001b[39m - Day \u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m \u001b[39m\u001b[39m+\u001b[39m\u001b[39m \u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array: array is 1-dimensional, but 2 were indexed"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_5_day_results(actual, predicted, column_name):\n",
    "    plt.figure(figsize=(15, 10))\n",
    "\n",
    "    for i in range(5):\n",
    "        plt.subplot(3, 2, i + 1)\n",
    "        plt.plot(actual[:, i], label='Actual Day ' + str(i + 1))\n",
    "        plt.plot(predicted[:, i], label='Predicted Day ' + str(i + 1))\n",
    "        plt.title(f'{column_name} - Day {i + 1}')\n",
    "        plt.xlabel('Time')\n",
    "        plt.ylabel('Price')\n",
    "        plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Use this function to plot your results\n",
    "plot_5_day_results(price_actual_array, price_predicted_array, target_column_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First results\n",
    "The model overall is great.\n",
    "It gets the tends and a mean absolute percentage error of 1.28% is not bad to make general predictions.\n",
    "\n",
    "But probably not for trading. Let's try to get it better: can I filter out some predictions?\n",
    "\n",
    "### Assumption:\n",
    "- I don't need it to be accurate 100% of the times\n",
    "\n",
    "Let's try to assess how much the model is sure about the prediction it is doing.\n",
    "\n",
    "## 1st try\n",
    "I added a dropout layer in the end to try to calculate a standard deviation on the model.\n",
    "- The correlation between the error and the standard deviation is almost 0, it is not working.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_mc_dropout(model, data, num_samples=100):\n",
    "    model.trainable = True \n",
    "    predictions = np.array([model.predict(data) for _ in range(num_samples)])\n",
    "    mean_predictions = predictions.mean(axis=0).flatten()\n",
    "    std_predictions = predictions.std(axis=0).flatten()\n",
    "    return mean_predictions, std_predictions\n",
    "\n",
    "predictions_array, pred_std_array = predict_with_mc_dropout(model, test_data, num_samples=300)\n",
    "\n",
    "# Denormalize predictions and standard deviations\n",
    "predictions_denorm = scaler_target.inverse_transform(predictions_array.reshape(-1, 1)).flatten()\n",
    "std_devs_denorm = pred_std_array * scaler_target.scale_\n",
    "\n",
    "errors = np.abs(predictions_denorm - price_actual_array)\n",
    "\n",
    "plt.scatter(std_devs_denorm, errors)\n",
    "plt.xlabel('Standard Deviation')\n",
    "plt.ylabel('Absolute Error')\n",
    "plt.title('Uncertainty (Std Dev) vs Prediction Error')\n",
    "plt.show()\n",
    "\n",
    "correlation_coef = np.corrcoef(std_devs_denorm, errors)[0, 1]\n",
    "print(f'Correlation coefficient between standard deviation and absolute error: {correlation_coef}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(path_augmented_price)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
